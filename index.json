[{"content":"you have found my website somehow\nyou can find out more about me in the about section\nthere is the now section for my current life in progress\n","date":"2023-10-03","permalink":"/","section":"","summary":"you have found my website somehow","title":""},{"content":"","date":"2023-10-03","permalink":"/tags/french/","section":"Tags","summary":"","title":"french"},{"content":"","date":"2023-10-03","permalink":"/posts/","section":"Posts","summary":"","title":"Posts"},{"content":" authentification ssh par\nclés sur équipements cisco introduction # les équipements cisco (switchs, routeurs, asa\u0026hellip;) tournent sur une distribution gnu/linux cisco ios\nsera couvert la configuration \u0026amp; la connexion en ssh à un routeur \u0026amp; à un switch via une paire de clés ssh\nla démarche reste la même entre ces équipements, vu qu\u0026rsquo;ils tournent sur cisco ios\ngénération des clés # sera utilisée une vm ubuntu pour la génération des clés ssh\ncisco ios supporte uniquement l\u0026rsquo;algorithme de chiffrement rsa\nla taille de la clé est personnel (1024, 2048, 4096\u0026hellip;)\ngénération d\u0026rsquo;une paire de clés ssh dans ~/.ssh/ suivant l\u0026rsquo;algorithme de chiffrement rsa de longueur 4096 bits sans passphrase\nssh-keygen -t rsa -b 4096 -N \u0026#34;\u0026#34; -f \u0026#34;$HOME/.ssh/cisco-ssh\u0026#34; -t rsa choix de l\u0026rsquo;algorithme de chiffrement\n-b 4096 précision longueur de la clé\n-c \u0026quot;~/.ssh/cisco-ssh.key\u0026quot; définition emplacement\n-N \u0026quot;\u0026quot; indication passphrasse (nulle)\nclé privée ~/.ssh/cisco-ssh \u0026amp; clé publique ~/.ssh/cisco-ssh.pub\nla clé publique devra être renseignée sur l\u0026rsquo;équipement cisco\npour afficher son contenu\ncat ~/.ssh/cisco-ssh.pub exemple de sortie de la commande\n1ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDPtiK1iUvKUFL6Ff8l9iR37yN4DdIR0CXAkLoRze/WY1sEHz1qwDThApO31WVhJRoxzGwIMNyQjbWDWUH5GvcPPipzyp5U1chwNsYWa4KiXgvBh/iVEq+a4kr0I/4jPJJXkjWNeBplLkYAYRIGF8w4CuQPHE0mjRuAzxTtuvFOD6ZaIP+kEWmoLrDCRPorW2y3WV6/fGLuDoLnS6v32qcxTS5bevpy9Iqw8Y4mVRpIHbQsnKNo3HZY5aOC0bxWCZ6m+EVXJnD5UiQbZmikPVGKqydKgEr/ZuqEjKKFiB+ETTIjYqFM7HjuurVenEiJ0BlVkp8B6aOIbpypp4skZfi1 xeylou@UPPA20102 le contenu effectif de la clé devra être utilisé (sans le ssh-rsa au début \u0026amp; le commentaire en fin)\nsauvegarde de la clé sans ssh-rsa \u0026amp; le commentaire xeylou@UPPA20102\ncat ~/.ssh/cisco-ssh.pub | sed \u0026#34;s/ssh-rsa //g\u0026#34; | sed \u0026#34;s/ xeylou@UPPA20102//g\u0026#34; \u0026gt; ~/.ssh/cisco-ssh.pub contenu de la clé effective ~/.ssh/cisco-ssh.pub\n1AAAAB3NzaC1yc2EAAAADAQABAAABAQDPtiK1iUvKUFL6Ff8l9iR37yN4DdIR0CXAkLoRze/WY1sEHz1qwDThApO31WVhJRoxzGwIMNyQjbWDWUH5GvcPPipzyp5U1chwNsYWa4KiXgvBh/iVEq+a4kr0I/4jPJJXkjWNeBplLkYAYRIGF8w4CuQPHE0mjRuAzxTtuvFOD6ZaIP+kEWmoLrDCRPorW2y3WV6/fGLuDoLnS6v32qcxTS5bevpy9Iqw8Y4mVRpIHbQsnKNo3HZY5aOC0bxWCZ6m+EVXJnD5UiQbZmikPVGKqydKgEr/ZuqEjKKFiB+ETTIjYqFM7HjuurVenEiJ0BlVkp8B6aOIbpypp4skZfi1 la clé publique est en une seule ligne\ncisco ios supporte maximum 254 caractères par ligne de commande\nla clé sera renseignée par paquets équivalents de 72 octets\nfold -b -w 72 ~/.ssh/cisco-ssh.pub exemple de sortie de la commande\n1ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDPtiK1iUvKUFL6Ff8l9iR37yN4DdIR0CXAkLoRze/WY1sEHz1qwDThApO31WVh 2JRoxzGwIMNyQjbWDWUH5GvcPPipzyp5U1chwNsYWa4KiXgvBh/iVEq+a4kr0I/4jPJJXkjWNeBplLkYAYRIGF8w4CuQPHE0mjRuA 3zxTtuvFOD6ZaIP+kEWmoLrDCRPorW2y3WV6/fGLuDoLnS6v32qcxTS5bevpy9Iqw8Y4mVRpIHbQsnKNo3HZY5aOC0bxWCZ6m+EVX 4JnD5UiQbZmikPVGKqydKgEr/ZuqEjKKFiB+ETTIjYqFM7HjuurVenEiJ0BlVkp8B6aOIbpypp4skZfi1 ce sera le contenu à coller dans la configuration de l\u0026rsquo;équipement\nNote pour le copier : selectionner dans le terminal puis CTRL + ↑ + C configuration routeur # modèle 2901 configuré comme suivant\nenable configure terminal hostname GASPARD no ip domain-lookup génération d\u0026rsquo;une clé rsa de 4096 bits pour initier l\u0026rsquo;environnement ssh\nrenseignement d\u0026rsquo;un domaine contingeant à sa création\nip domain-name rzo.local crypto key generate rsa modulus 4096 création d\u0026rsquo;un utilisateur pour la connexion\nutilisation de l\u0026rsquo;algorithme de chiffrement sha256 au lieu de md5 par défaut (256 bits contre 128)\nusername xeylou privilege 15 algorithm-type sha256 secret motdepasse privilege 15 mêmes permissions que enable\nalgorithm-type sha256 choix méthode de chiffrement mot de passe\nsecret motdepasse définition d\u0026rsquo;un mot de passe (optionnel)\nles lignes virtuelles sont des supports pour accèder à l\u0026rsquo;interface de commande cisco à distance\nles anciennes versions de cisco ios en ont 5 (0-4) sinon 16 (0-15)\nconfiguration des lignes virtuelles pour y accèder uniquement par une connexion en ssh enregistrée sur la base d\u0026rsquo;utilisateur locale\nline vty 0 15 transport input ssh login local passage de ssh version 1 à 2 (désactivation de la version 1)\nip ssh version 2 importation de la clé publique à l\u0026rsquo;utilisateur xeylou\nip ssh pubkey-chain username xeylou key-string coller la clé effective ici\npour indiquer la fin de la clé\nexit désacitvation de tous les types d\u0026rsquo;authentification sauf par clé ssh (publickey)\nno ip ssh server authenticate user password no ip ssh server authenticate user keyboard attribution d\u0026rsquo;un adresse ip à une des interfaces\nint g0/0 ip address 192.168.0.1 255.255.255.0 no shut configuration switch # la configuration ssh est identique\nen conf t hostname GASPARD ip domain-name rzo.lan crypto key generate rsa modulus 4096 username xeylou privilege 15 algorithm-type sha256 secret motdepasse line vty 0 15 login local transport input ssh ip ssh version 2 ip ssh pubkey-chain username xeylou key-string renseignement contenu effectif de la clé\nexit no ip ssh server authenticate user password no ip ssh server authenticate user keyboard configuration interface d\u0026rsquo;accès qui sera un vlan ici présents sur tous les ports par défaut\nint vlan 1 ip add 192.168.0.2 255.255.255.0 no shut connexion ssh # configuration des commandes ssh gaspard ou ssh sw7 pour se connecter aux équipements\nnano ~/.ssh/config fichier de configuration/d\u0026rsquo;alias des machines clientes ssh\ncisco ios utilise des protocoles obsolètes que openssh refuse d\u0026rsquo;utiliser par défaut\nrenseignement de ceux-ci dans la configuration des alias\npour le routeur\n1Host gaspard 2 hostname = 192.168.0.1 3 user = xeylou 4 KexAlgorithms = diffie-hellman-group-exchange-sha1 5 HostKeyAlgorithms = ssh-rsa 6 PubKeyAcceptedAlgorithms = ssh-rsa 7 IdentityFile \u0026#34;~/.ssh/cisco-ssh\u0026#34; KexAlgorithms changement d\u0026rsquo;algorithme d\u0026rsquo;échange de clé HostKeyAlgorithms chiffrement proposé par la vm ubuntu PubKeyAcceptedAlgorithms par l\u0026rsquo;équipement\nmanipulation supplémentaire à faire pour le switch\nles ciphers vont définir l\u0026rsquo;algorithme utilisé pour sécuriser la connexion ssh (ne pas transmettre en clair dès le départ)\nrajout d\u0026rsquo;une ligne pour en définir un supporté par les switchs\n1Host sw7 2 hostname = 192.168.0.2 3 user = xeylou 4 KexAlgorithms = diffie-hellman-group-exchange-sha1 5 HostKeyAlgorithms = ssh-rsa 6 PubKeyAcceptedAlgorithms = ssh-rsa 7 IdentityFile \u0026#34;~/.ssh/cisco-ssh\u0026#34; 8 Ciphers aes256-cbc tentative de connexion depuis vm ubuntu\nssh gaspard ssh sw7 supplément # vérification concordance des clés\nsur les équipements\nshow running-config | begin pubkey comparable au hash sur la vm ubuntu\nssh-keygen -l -f $HOME/.ssh/cisco-ssh.key.pub définition d\u0026rsquo;une acl pour accepter uniquemennt les adresses ip locales à se connecter en ssh\nen conf t ip access-list standard SSH_ACL permit 192.168.0.0 0.0.0.255 line vty 0 15 access-class SHH_ACL in ajout d\u0026rsquo;un timeout de 10 minutes (inactivité) sinon infini\nexec timeout 10 0 définition de maximum 3 tentative de connexion ralentissement bruteforce\nip ssh authentication-retries 3 service tcp-keepalives-in service tcp-keepalives-out activation de scp pour transfert de fichiers via ssh\nip scp server enable ","date":"2023-10-03","permalink":"/posts/ssh-cisco-ios/","section":"Posts","summary":"authentification ssh par","title":"ssh cisco ios"},{"content":"","date":"2023-10-03","permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"","date":"2023-10-03","permalink":"/tags/workshop/","section":"Tags","summary":"","title":"workshop"},{"content":"","date":"2023-09-30","permalink":"/tags/dns/","section":"Tags","summary":"","title":"dns"},{"content":"","date":"2023-09-30","permalink":"/tags/mail/","section":"Tags","summary":"","title":"mail"},{"content":" installation d\u0026rsquo;un serveur mail mx postfix, utilisation avec dovecot \u0026amp; thunderbird introduction # meilleure lecture en mode sombre, coin haut droit\nje continue l\u0026rsquo;avancée des workshops avec un serveur mail postfix pour l\u0026rsquo;envoi \u0026amp; la réception de mails\nil pourra être utilisé avec utilisateurs gnu/linux ou virtuels\n%%{init: {'theme':'dark'}}%% graph TD subgraph 192.168.122.0/24 postfix[r303-deb12-postfix\n192.168.122.10] bind9[r303-deb12-bind9\n192.168.122.11] thunderbird[r303-deb12-client\n192.168.122.12] pstf(Service Postfix) bind(Service Bind9) clients(Mozilla Thunderbird) gw{NAT\n192.168.122.1} end wan{WAN} wan --- gw gw --- postfix \u0026 bind9 gw --- thunderbird postfix -.- pstf bind9 -.- bind thunderbird -.- clients vm postfix # modification nom d\u0026rsquo;hôte\nhostnamectl set-hostname r303-deb12-postfix attribution adresse ip statique\nnano /etc/network/interfaces 4source /etc/network/interfaces.d/* 5 6# The loopback network interface 7auto lo 8iface lo inet loopback 9 10# The primary network interface 11allow-hotplug enp1s0 12iface enp1s0 inet static 13address 192.168.122.10/24 14gateway 192.168.122.1 systemctl restart networking installation paquet postfix \u0026amp; mailutils pour envoi/réception de mails entre utilisateurs\napt install -y postfix mailutils Internet Site -\u0026gt; rzo.lan\npour que postfix propose de prendre un nom de domaine, qui sera finalement utilisé pour les mails\nsi installation bien déroulée : service postfix actif\nsystemctl status postfix fichier de configuration global postfix /etc/postfix/main.cf\ncommente tout ce qui touche au tls car pas utilisé\najout informations pour utilisation du service\nnano /etc/postfix/main.cf 26# TLS parameters 27# smtpd_tls_cert_file=/etc/ssl/certs/ssl-cert-snakeoil.pem 28# smtpd_tls_key_file=/etc/ssl/private/ssl-cert-snakeoil.key 29# smtpd_tls_security_level=may 30 31# smtp_tls_CApath=/etc/ssl/certs 32# smtp_tls_security_level=may 33# smtp_tls_session_cache_database = btree:${data_directory}/smtp_scache 34 35 36mydomain = rzo.lan 37# smtpd_relay_restrictions = permit_mynetworks permit_sasl_authenticated defer_unauth_destination 38myhostname = r303-deb12-postfix.rzo.lan 39alias_maps = hash:/etc/aliases 40alias_database = hash:/etc/aliases 41myorigin = /etc/mailname 42mydestination = $mydomain, $myhostname, localhost.$mydomain, localhost 43# relayhost = 44mynetworks = 127.0.0.0/8 192.168.122.0/24 45home_mailbox = Maildir/ 46mailbox_size_limit = 51200000 47recipient_delimiter = + 48inet_interfaces = all 49inet_protocols = ipv4 alias_maps table des noms \u0026amp; des adresses de mydestination\nalias_database table des noms d\u0026rsquo;usages de alias_maps\nmyorigin pas de nom de domaine -\u0026gt; ajoute celui dans fichier\nmydestination domaines acceptés d\u0026rsquo;échange\nrecipient_delimiter truc@$mydomain \u0026amp; truc+random@$mydomain == les mêmes (pourriel)\nvérification syntaxique après édition\npostfix check redémarrage du service pour appliquer les modifications\nsystemctl restart postfix création de deux users gnu/linux\nNote mot de passe contingeant à l\u0026rsquo;authentification\u0026hellip; adduser --gecos \u0026#34;\u0026#34; user1 \u0026amp;\u0026amp; adduser --gecos \u0026#34;\u0026#34; user2 connexion à l\u0026rsquo;un des deux users pour test d\u0026rsquo;envoi\nsu user1 mail user2 Cc:\nSubject: test envoi user2\ncontenu du mail\nenvoi avec retour à la ligne puis CTRL + D\nconnexion sur l\u0026rsquo;utilisateur récepteur\nsu user2 vérification de la réception du mail\nls ~/Maildir/new/ | wc -l 1 si nouveau mail car fichier dans ~/Maildir/new/\ndossier ~/Maildir défini dans /etc/postfix/main.cf\ndovecot # serveur imap \u0026amp; pop3\ninstallation du daemon imap de dovecot\napt install -y dovecot-imapd autres paquets dans la suite dovecot-*, e.g. dovecot-ldap pour support ldap\nfichiers de configuration de dovecot dans /etc/dovecot/conf.d/\nmodification des méthodes d\u0026rsquo;authentification\nnano /etc/dovecot/conf.d/10-auth.conf précision de tout laisser passer en clair\n5# Disable LOGIN command and all other plaintext authentications unless 6# SSL/TLS is used (LOGINDISABLED capability). Note that if the remote IP 7# matches the local IP (ie. you\u0026#39;re connecting from the same computer), the 8# connection is considered secure and plaintext authentication is allowed. 9# See also ssl=required setting. 10disable_plaintext_auth = no définition des méchanismes d\u0026rsquo;authentification (login obsolète mais toujours utilisé)\n96# Space separated list of wanted authentication mechanisms: 97# plain login digest-md5 cram-md5 ntlm rpa apop anonymous gssapi otp 98# gss-spnego 99# NOTE: See also disable_plaintext_auth setting. 100auth_mechanisms = plain login modification de l\u0026rsquo;emplacement de destination des mails\nnano /etc/dovecot/conf.d/10-mail.conf 22# See doc/wiki/Variables.txt for full list. Some examples: 23# 24# mail_location = maildir:~/Maildir 25# mail_location = mbox:~/mail:INBOX=/var/mail/%u 26# mail_location = mbox:/var/mail/%d/%1n/%n:INDEX=/var/indexes/%d/%1n/%n 27# 28# \u0026lt;doc/wiki/MailLocation.txt\u0026gt; 29# 30mail_location = maildir:~/Maildir modification de la gestion des logs - a été utile\nnano /etc/dovecot/conf.d/10-logging.conf 5# Log file to use for error messages. \u0026#34;syslog\u0026#34; logs to syslog, 6# /dev/stderr logs to stderr. 7log_path = /var/log/dovecot.log 8 9# Log file to use for informational messages. Defaults to log_path. 10#info_log_path = 11# Log file to use for debug messages. Defaults to info_log_path. 12#debug_log_path = 13 14# Syslog facility to use if you\u0026#39;re logging to syslog. Usually if you don\u0026#39;t 15# want to use \u0026#34;mail\u0026#34;, you\u0026#39;ll use local0..local7. Also other standard 16# facilities are supported. 17syslog_facility = mail 39# Log unsuccessful authentication attempts and the reasons why they failed. 40auth_verbose = yes 50# Even more verbose logging for debugging purposes. Shows for example SQL 51# queries. 52auth_debug = yes application des modifications\nsystemctl restart dovecot vérification du fonctionnement\ntelnet -l user1 localhost 143 a login user2 user2\noù user2 l\u0026rsquo;utilisateur et le mot de passe\nutilisateurs virtuels # création user vmail avec /opt/messagerie comme home directory\ngroupe vmail avec group id de 5000\ngroupadd -g 5000 vmail création du user\nuseradd -g vmail -u 5000 vmail -d /opt/messagerie -m -g son groupe\n-u user id de 5000\n-d son répertoire utilisateur/home ~\n-m créer son ~ si inexistant\nindication à postfix de vmail \u0026amp; repertoire /opt/messagerie pour la gestion des boites aux lettres\nnano /etc/postfix/main.cf 26# TLS parameters 27# smtpd_tls_cert_file=/etc/ssl/certs/ssl-cert-snakeoil.pem 28# smtpd_tls_key_file=/etc/ssl/private/ssl-cert-snakeoil.key 29# smtpd_tls_security_level=may 30 31# smtp_tls_CApath=/etc/ssl/certs 32# smtp_tls_security_level=may 33# smtp_tls_session_cache_database = btree:${data_directory}/smtp_scache 34 35 36mydomain = rzo.lan 37# smtpd_relay_restrictions = permit_mynetworks permit_sasl_authenticated defer_unauth_destination 38myhostname = r303-deb12-postfix.rzo.lan 39alias_maps = hash:/etc/aliases 40alias_database = hash:/etc/aliases 41myorigin = /etc/mailname 42mydestination = $mydomain, $myhostname, localhost.$mydomain, localhost 43default_transport = dovecot 44mail_spool_directory = /opt/messagerie/ 45virtual_mailbox_base = /opt/messagerie/ 46virtual_mailbox_domains = hash:/etc/postfix/vdomain 47virtual_mailbox_maps = hash:/etc/postfix/vmail 48virtual_alias_maps = hash:/etc/postfix/valias 49virtual_uid_maps = static:5000 50virtual_gid_maps = static:5000 51# relayhost = 52mynetworks = 127.0.0.0/8 192.168.122.0/24 53home_mailbox = Maildir/ 54mailbox_size_limit = 51200000 55recipient_delimiter = + 56inet_interfaces = all 57inet_protocols = ipv4 default_transport protocole/serveur d\u0026rsquo;envoi, par défaut smtp\nmail_spool_directory dossier de stockage des mails\nvirtual_mailbox_domains liste domaines où postfix destinataire\nvirtual_mailbox_maps adresses valides de virtual_mailbox_domains\nvirtual_uid_maps user id pour écrire les mails\nvirtual_uid_maps pareil que virtual_uid_maps pour group id\ndéfinition du domaine virtuel\nnano /etc/postfix/vdomain Note pas le droit être le même que celui dans postfix 1rzo.private # création de messageries virtuelles accordément virtual_mailbox_maps\nnano /etc/postfix/vmail 1xeylou@rzo.private rzo.private/xeylou/ 2testing@rzo.private rzo.private/testing/ 3admin@rzo.private rzo.private/admin/ définition des alias virtuels pour ces utilisateurs vu virtual_alias_maps\nnano /etc/postfix/valias 1root: admin@rzo.private 2xeylou: xeylou@rzo.private création d\u0026rsquo;un daemon postfix pour dovecot/vmail\nnano /etc/postfix/master.cf 138dovecot unix - n n - - pipe 139 flags=DRhu user=vmail:vmail argv=/usr/lib/dovecot/deliver -f ${sender} -d ${recipient} prise en compte des 3 fichiers modifiés\npostmap /etc/postfix/vdomain postmap /etc/postfix/vmail postalias /etc/postfix/valias postfix check modification dovecot # utilisation des comptes virtuels avec authentification correcte\nmodification de la méthode d\u0026rsquo;accès\nnano /etc/dovecot/conf.d/10-auth.conf 5# Disable LOGIN command and all other plaintext authentications unless 6# SSL/TLS is used (LOGINDISABLED capability). Note that if the remote IP 7# matches the local IP (ie. you\u0026#39;re connecting from the same computer), the 8# connection is considered secure and plaintext authentication is allowed. 9# See also ssl=required setting. 10disable_plaintext_auth = yes ajout d\u0026rsquo;une méthode d\u0026rsquo;authentification sécurisée\n96# Space separated list of wanted authentication mechanisms: 97# plain login digest-md5 cram-md5 ntlm rpa apop anonymous gssapi otp 98# gss-spnego 99# NOTE: See also disable_plaintext_auth setting. 100auth_mechanisms = cram-md5 plain login ajout du fichier auth-static.conf.ext dans la configuration\n122#!include auth-system.conf.ext 123#!include auth-sql.conf.ext 124#!include auth-ldap.conf.ext 125#!include auth-passwdfile.conf.ext 126#!include auth-checkpassword.conf.ext 127!include auth-static.conf.ext définition emplacement liste utilisateurs virtuels + mots de passe\nnano /etc/dovecot/conf.d/auth-static.conf.ext 16passdb { 17# driver = static 18# args = password=test 19 driver = passwd-file 20 args = username_format=%u /etc/dovecot/dovecot.users 21} 22 23userdb { 24# driver = static 25# args = uid=vmail gid=vmail home=/home/%u 26 driver = static 27 args = uid=vmail gid=vmail home=/opt/messagerie/%d/%n/ allow_all_users=yes 28} informations user vmail pour récupération mails\nnano /etc/dovecot/conf.d/10-mail.conf 105# System user and group used to access mails. If you use multiple, userdb 106# can override these by returning uid or gid fields. You can use either numbers 107# or names. \u0026lt;doc/wiki/UserIds.txt\u0026gt; 108mail_uid = 5000 109mail_gid = 5000 110 111# Group to enable temporarily for privileged operations. Currently this is 112# used only with INBOX when either its initial creation or dotlocking fails. 113# Typically this is set to \u0026#34;mail\u0026#34; to give access to /var/mail. 114mail_privileged_group = vmail définition autorisations pour lister utilisateurs\nnano /etc/dovecot/conf.d/10-master.conf 100 unix_listener auth-userdb { 101 #mode = 0666 102 user = vmail 103 group = vmail 104 } 105 106 unix_listener /var/spool/postfix/private/auth { 107 mode = 0666 108 user = postfix 109 group = postfix 110 } définition du hash des mots de passe des vusers\ndoveadm pw -s CRAM-MD5 Enter new password:\nRetype new password:\n{CRAM-MD5}e02d374fde0dc75a17a557039a3a5338c7743304777dccd376f332bee68d2cf6\ncollé dans /etc/dovecot/dovecot.users défini /etc/dovecot/conf.d/auth-static.conf.ext\ndéfinition mots de passe vusers\nnano /etc/dovecot/dovecot.users 1xeylou@rzo.private:{CRAM-MD5}e02d374fde0dc75a17a557039a3a5338c7743304777dccd376f332bee68d2cf6 2testing@rzo.private:{CRAM-MD5}e02d374fde0dc75a17a557039a3a5338c7743304777dccd376f332bee68d2cf6 3admin@rzo.private:{CRAM-MD5}e02d374fde0dc75a17a557039a3a5338c7743304777dccd376f332bee68d2cf6 redémarrage des deux services\nsystemctl restart postfix systemctl restart dovecot vérification de leur fonctionnement\nsystemctl status postfix systemctl status dovecot pour débogger\njournalctl -xfe un des problèmes importants que j\u0026rsquo;ai eu\nOct 02 09:01:33 r303-deb12-postfix postfix/pipe[2905]: 940265FD8B: to= xeylou@rzo.private, relay=dovecot, delay=0.04, delays=0.02/0/0/0.02, dsn=4.3.0, status=deferred (temporary failure. Command output: lda( xeylou@rzo.private): Error: net_connect_unix(/run/dovecot/stats-writer) failed: Permission denied Can\u0026rsquo;t open log file /var/log/dovecot.log: Permission denied )\ncorrectif\nchown vmail:vmail /var/log/dovecot.log vm bind9 # installation du paquet bind9 + dépendances\napt install -y dbus bind9* dnsutils modification zones dns dans etc/bind/named.conf.local\nnano /etc/bind/named.conf.local 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // // Do any local configuration here // // Consider adding the 1918 zones here, if they are not used in your // organization //include \u0026#34;/etc/bind/zones.rfc1918\u0026#34;; zone \u0026#34;rzo.lan\u0026#34; IN { type master; file \u0026#34;/etc/bind/rzo.lan\u0026#34;; }; zone \u0026#34;rzo.private\u0026#34; IN { type master; file \u0026#34;/etc/bind/rzo.private\u0026#34;; }; zone \u0026#34;122.168.192.in-addr.arpa\u0026#34; { type master; file \u0026#34;/etc/bind/rzo.lan.inverse\u0026#34;; }; vérification syntaxique\nnamed-checkconf /etc/bind/named.conf.local édition de celles-ci\nnano /etc/bind/rzo.lan 1$TTL 86400 2$ORIGIN rzo.lan. 3 4@ IN SOA ns.rzo.lan. admin.rzo.lan. ( 52023100101 ; serial 621600 ; refresh 710800 ; retry 843200 ; expire 910800 ) ; minimum 10 11@ IN NS ns.rzo.lan. 12@ IN MX 10 mail.rzo.lan. 13mail IN A 192.168.122.10 14ns IN A 192.168.122.11 15postfix IN CNAME mail 16bind1 IN CNAME ns nano /etc/bind/rzo.private 1$TTL 86400 2$ORIGIN rzo.private. 3 4@ IN SOA ns.rzo.private. admin.rzo.private. ( 52023100201 ; serial 621600 ; refresh 710800 ; retry 843200 ; expire 910800 ) ; minimum 10 11@ IN NS ns.rzo.private. 12@ IN MX 10 mail.rzo.private. 13mail IN A 192.168.122.10 14ns IN A 192.168.122.11 15postfix IN CNAME mail 16bind1 IN CNAME ns nano /etc/bind/rzo.lan.inverse 1$TTL 86400 2 3@ IN SOA ns.rzo.lan. admin.rzo.lan. ( 42023100101 ; serial 521600 ; refresh 610800 ; retry 743200 ; expire 810800 ) ; minimum 9 10@ IN NS ns. 1111 IN PTR ns 1210 IN PTR mail named-checkzone rzo.lan /etc/bind/rzo.lan named-checkzone rzo.private /etc/bind/rzo.private named-checkzone rzo.lan.inverse /etc/bind/rzo.lan.inverse systemctl restart bind9 test sur machine extérieure - après modification dns\ndig ns.rzo.lan dig mail.rzo.lan dig -x 192.168.122.11 dig -x 192.168.122.10 vm thunderbird # apt install -y thunderbird connexion utilisateur virtuel xeylou\npareil pour testing\nenvoi du premier mail\nmail peut être visualisé sur vm postfix/dovecot\nls /opt/messagerie/rzo.private/testing/Maildir/.Sent/cur/ ","date":"2023-09-30","permalink":"/posts/postfix-workshop/","section":"Posts","summary":"installation d\u0026rsquo;un serveur mail mx postfix, utilisation avec dovecot \u0026amp; thunderbird introduction # meilleure lecture en mode sombre, coin haut droit","title":"postfix workshop"},{"content":" installation d\u0026rsquo;une infrastructure dns bind9 introduction # les deux premiers tp portent sur l\u0026rsquo;installation d\u0026rsquo;une infrastructure dns avec des serveurs bind9\nje n\u0026rsquo;ai pas fait les notions \u0026ldquo;transversales\u0026rdquo; : gestion des logs \u0026amp; les acl\nessayez de comprendre ce qu\u0026rsquo;il se fait, lire vraiment attentivement plutôt que de le refaire en copiant \u0026amp; en collant\npour nous le qcm sur bind9 \u0026amp; postfix sera le 18 ou le 19 octobre, sur des notions de cours, td, tp\npas de points négatifs, pas de choix multiples -\u0026gt; une seule réponse possible\nexplications # j\u0026rsquo;utilise 3 vm debian 12 : r303-deb12-host1, r303-deb12-bind1 \u0026amp; r303-deb12-bind2\nle réseau local des vm est le 192.168.122.0/24 avec leur passerelle par défaut en 192.168.122.1\n%%{init: {'theme':'dark'}}%% graph TD subgraph 192.168.122.0/24 host1[r303-deb12-host1\n.2] bind1[r303-deb12-bind1\n.3] srv-bind(Service Bind9) srv-bind2(Service Bind9) bind2[r303-deb12-bind2\n.4] gw{NAT\n.1} end wan{WAN} wan --- gw gw --- host1 \u0026 bind1 gw --- bind2 bind1 -.- srv-bind bind2 -.- srv-bind2 j\u0026rsquo;utilise debian d\u0026rsquo;habitude \u0026amp; mr. le prof veut nous faire accèder en ssh à ces vm, \u0026amp; ne pas utiliser l\u0026rsquo;environnement de bureau des ubuntu\nconfiguration initiale # pour éviter d\u0026rsquo;avoir root@debian sur toutes les vm en ssh, je change leur hostname pour avoir root@serveur-bind-1 par exemple\nlors des manipulations en terminal, ça évite de se tromper entre qui est qui \u0026amp; de rentrer une commande dans la mauvaise vm\nNote commande effectuée en permission root sur les 3 vm en changeant nouveau_hostname hostnamectl set-hostname nouveau_hostname \u0026amp;\u0026amp; logout je change aussi les ip des vm de manière statique dans /etc/network/interfaces\nnano /etc/network/interfaces je supprime la ligne indiquant de se référer au dhcp (si elle existe): inet iface enp1s0 dhcp\n\u0026amp; je rajoute cette configuration selon l\u0026rsquo;interface, ici enp1s0 où X est le dernier octet de l\u0026rsquo;adresse des vm configurés sur le schéma\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # This file describes the network interfaces available on your system # and how to activate them. For more information, see interfaces(5). source /etc/network/interfaces.d/* # The loopback network interface auto lo iface lo inet loopback # The primary network interface # interface que vous avez auto enp1s0 iface enp1s0 inet static address 192.168.122.X netmask 255.255.255.0 gateway 192.168.122.1 pour me simplifier la connexion, j\u0026rsquo;autorise l\u0026rsquo;accès au compte root sur les vm en ssh - désactivé par défaut pour des raisons de sécurité\nen éditant le fichier /etc/ssh/sshd_config\nNote manipulation effectuée sur les 3 vm nano /etc/ssh/sshd_config en décommentant \u0026amp; changeant la valeur de cette variable\n30 31 32 33 34 35 36 # Authentication #LoginGraceTime 2m PermitRootLogin yes #StrictModes yes #MaxAuthTries 6 #MaxSessions 10 puis je redémarre le daemon ssh pour prendre la modification en compte\nsystemctl restart sshd je change aussi le mot de passe du compte root des vm pour root\npasswd root pour ne pas trop réflechir avec des ip - je le fais mais une erreur d\u0026rsquo;inattention dans une ip \u0026amp; tu y es pour 4h de deboggage\u0026hellip;\nsur la machine qui va accèder en ssh à tout le monde (machine physique), je crée des alias pour juste rentrer ssh bind \u0026amp; arriver sur le serveur bind par exemple - j\u0026rsquo;essaye d\u0026rsquo;être \u0026ldquo;fénéant intelligemment\u0026rdquo; 😄\nNote sur la machine physique nano ~/.ssh/config avec la configuration suivante\n1 2 3 4 5 6 7 8 9 10 11 host host1 Hostname 192.168.122.2 User root host bind1 Hostname 192.168.122.3 User root host bind2 Hostname 192.168.122.4 User root après ça je peux juste faire ssh host1 qui sera l\u0026rsquo;équivalent de ssh root@192.168.122.2\nconf. serveur bind1 # j\u0026rsquo;utiliserai le nom de domaine adehu.com\non accède au shell du serveur bind\nssh bind1 puis on installe les paquets nécessaires\napt install -y dbus bind9* dnsutils avant de débuter la config.:\nune zone inverse : on demande au serveur dns -\u0026gt; pour cette adresse ip, tu as quel domaine?\nce qui est l\u0026rsquo;inverse de -\u0026gt; j\u0026rsquo;ai ce nom de domaine, donne-moi son ip associée\ndans la zone inverse, on va mettre les mêmes enregistrements que ceux dans adehu.com, mais à l\u0026rsquo;envers du coup\non va aussi définir que ce serveur dns (bind1) est le serveur principal pour ces zones dns\ndans le fichier de gestion des zones /etc/bind/named.conf, on définit notre zone dns \u0026amp; sa zone inverse\nmême si la bonne pratique voudrait qu\u0026rsquo;il include notre fichier de conf.\nnano /etc/bind/named.conf contenant la configuration suivante\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // This is the primary configuration file for the BIND DNS server named. // // Please read /usr/share/doc/bind9/README.Debian for information on the // structure of BIND configuration files in Debian, *BEFORE* you customize // this configuration file. // // If you are just adding zones, please do that in /etc/bind/named.conf.local include \u0026#34;/etc/bind/named.conf.options\u0026#34;; include \u0026#34;/etc/bind/named.conf.local\u0026#34;; include \u0026#34;/etc/bind/named.conf.default-zones\u0026#34;; zone \u0026#34;adehu.com\u0026#34; IN { type master; file \u0026#34;/etc/bind/adehu.com\u0026#34;; }; zone \u0026#34;122.168.192.in-addr.arpa\u0026#34; { type master; file \u0026#34;/etc/bind/adehu.com.inverse\u0026#34;; }; on fait référence à des fichiers qui seront la configuration de ces zones\ntype master: ce dns est le principal de cette zone dns\non peut aussi vérifier la syntaxe du fichier après l\u0026rsquo;enregistrement\nnamed-checkconf /etc/bind/named.conf configuration de la zone dns adehu.com\nnano /etc/bind/adehu.com 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 $TTL 86400 $ORIGIN adehu.com. @ IN SOA bind1.adehu.com. admin.adehu.com. ( 2023092702 ; serial 21600 ; refresh 10800 ; retry 43200 ; expire 10800 ) ; minimum @ IN NS bind1.adehu.com. @ IN NS bind2.adehu.com. guest.adehu.com. IN NS bind2 bind1 IN A 192.168.122.3 bind2 IN A 192.168.122.4 srv-bind1 IN CNAME bind1 srv-bind2 IN CNAME bind2 la directive $ORIGIN est là pour indiquer le domaine si un hôte est pas totalement défini\n@ IN SOA pour accorder qui a l\u0026rsquo;autorité sur cette zone (ici bind1) avec sa config.\nIN NS on fait le record d\u0026rsquo;un serveur dns (pour cette zone il y a deux serveurs dns)\nje rajoute un . à la fin des fqdn pour indiquer leur fin (sinon ils répètent leur domain.tld)\nguest.adehu.com. IN NS r303-deb12-bind2 on définit un sous domaine \u0026amp; on le délègue à bind2 -\u0026gt; si tu veux aller sur ce sous-domaine, va contacter lui. par contre faudra lui renseigner\nIN A pour les dns définis, faut bien leur ip (A pour ipv4)\nIN CNAME les serveurs bind seront accessibles via bindX.adehu.com\nles valeurs chiffrées je ne les ai pas sorti de mon chapeau mais de ce tableau d\u0026rsquo;équivalence (secondes -\u0026gt; instances de temps)\nnombres attrocesinstances de temps601 min180030 min36001 heure108003 heures216006 heures4320012 heures864001 jour259200\n3 jours6048001 semaine pour la zone inverse\nnano /etc/bind/adehu.com.inverse 1 2 3 4 5 6 7 8 9 10 11 12 13 $TTL 86400 @ IN SOA bind1.adehu.com. admin.adehu.com. ( 2023092701 ; serial 21600 ; refresh 10800 ; retry 43200 ; expire 10800 ) ; minimum @ IN NS bind1. @ IN NS bind2. 11 IN PTR bind1 12 IN PTR bind2 IN PTR le nombre au début = dernier octet de l\u0026rsquo;ip voulue, on enregistre un pointeur (ptr) vers tel machine\non vérifie la syntaxe\nnamed-checkzone adehu.com /etc/bind/adehu.com named-checkzone adehu.com.inverse /etc/bind/adehu.com.inverse redémarrer le service bind9 pour prendre en compte les modifications\nsystemctl restart bind9 Mettez dans le /etc/resolv.conf de votre machine host1 l\u0026rsquo;ip de votre serveur bind1 pour l\u0026rsquo;avoir en tant que dns nano /etc/resolv.conf 1 nameserver 192.168.122.3 vérifier l\u0026rsquo;installation\ntous les tests en dessous fonctionnaient\n# pour tester un domaine: dig domain.tld dig adehu.com # connaitre les serveurs dns gérant un domaine: dig NS domain.tld dig NS adehu.com # résoudre un nom: dig sub-domain.domain.tld dig bind1.adehu.com dig bind2.adehu.com # tester la zone inverse: nslookup ip-machine-a-joindre nslookup 192.168.122.3 nslookup 192.168.122.4 deuxième serveur bind # je vais partager la gestion de la zone adehu.com au deuxième serveur dns r303-deb12-bind2, le serveur bind1 sera le serveur dns primaire (master) \u0026amp; bind2 le secondaire (secondary)\non autorise le transfert de la zone adehu.com vers le serveur bind2 r303-deb12-bind2\nNote sur r303-deb12-bind1 nano /etc/bind/named.conf 1// This is the primary configuration file for the BIND DNS server named. 2// 3// Please read /usr/share/doc/bind9/README.Debian for information on the 4// structure of BIND configuration files in Debian, *BEFORE* you customize 5// this configuration file. 6// 7// If you are just adding zones, please do that in /etc/bind/named.conf.local 8 9include \u0026#34;/etc/bind/named.conf.options\u0026#34;; 10include \u0026#34;/etc/bind/named.conf.local\u0026#34;; 11include \u0026#34;/etc/bind/named.conf.default-zones\u0026#34;; 12 13zone \u0026#34;adehu.com\u0026#34; IN { 14 type master; 15 file \u0026#34;/etc/bind/adehu.com\u0026#34;; 16 allow-transfer { 192.168.122.4; }; 17}; 18 19zone \u0026#34;122.168.192.in-addr.arpa\u0026#34; { 20 type master; 21 file \u0026#34;/etc/bind/adehu.com.inverse\u0026#34;; 22 allow-transfer { 192.168.122.4; }; 23}; on redémarre le service bind\nsystemctl restart bind9 on doit informer le deuxième serveur bind qu\u0026rsquo;il a cette zone avec r303-deb12-bind1 en serveur dns maitre\nj\u0026rsquo;ajoute aussi le sous domaine qu\u0026rsquo;il lui a été attribué\nNote sur r303-deb12-bind2 nano /etc/bind/named.conf 1// This is the primary configuration file for the BIND DNS server named. 2// 3// Please read /usr/share/doc/bind9/README.Debian for information on the 4// structure of BIND configuration files in Debian, *BEFORE* you customize 5// this configuration file. 6// 7// If you are just adding zones, please do that in /etc/bind/named.conf.local 8 9include \u0026#34;/etc/bind/named.conf.options\u0026#34;; 10include \u0026#34;/etc/bind/named.conf.local\u0026#34;; 11include \u0026#34;/etc/bind/named.conf.default-zones\u0026#34;; 12 13zone \u0026#34;adehu.com\u0026#34; IN { 14 type slave; 15 file \u0026#34;/etc/bind/adehu.com\u0026#34;; 16 masters { 192.168.122.3; }; 17}; 18 19zone \u0026#34;122.168.192.in-addr.arpa\u0026#34; { 20 type slave; 21 file \u0026#34;/etc/bind/adehu.com.inverse\u0026#34;; 22 masters { 192.168.122.3; }; 23 24zone \u0026#34;guest.adehu.com\u0026#34; IN { 25 type master; 26 file \u0026#34;/etc/bind/guest.adehu.com\u0026#34;; 27}; on lui renseigne les zones\nnano /etc/bind/adehu.com c\u0026rsquo;est le même que l\u0026rsquo;autre\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 $TTL 86400 $ORIGIN adehu.com. @ IN SOA bind1.adehu.com. admin.adehu.com. ( 2023092702 ; serial 21600 ; refresh 10800 ; retry 43200 ; expire 10800 ) ; minimum @ IN NS bind1.adehu.com. @ IN NS bind2.adehu.com. guest.adehu.com. IN NS bind2 bind1 IN A 192.168.122.3 bind2 IN A 192.168.122.4 srv-bind1 IN CNAME bind1 srv-bind2 IN CNAME bind2 y compris la zone inverse\nnano /etc/bind/adehu.com.inverse c\u0026rsquo;est le même que l\u0026rsquo;autre\n1 2 3 4 5 6 7 8 9 10 11 12 13 $TTL 86400 @ IN SOA bind1.adehu.com. admin.adehu.com. ( 2023092702\u0026amp; ; serial 21600 ; refresh 10800 ; retry 43200 ; expire 10800 ) ; minimum @ IN NS bind1. @ IN NS bind2. 11 IN PTR bind1 12 IN PTR bind2 vu qu\u0026rsquo;on a délegué un sous-domaine ici, il faut l\u0026rsquo;indiquer\nnano /etc/bind/guest.adehu.com 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 $TTL 86400 $ORIGIN guest.adehu.com. @ IN SOA guest.adehu.com. guest.adehu.com. ( 2023092702 ; serial 21600 ; refresh 10800 ; retry 43200 ; expire 10800 ) ; minimum @ IN NS bind2.guest.adehu.com. adehu.com. IN NS bind1.adehu.com. adehu.com. IN NS bind2.adehu.com. bind1.adehu.com. IN A 192.168.122.3 bind2.adehu.com. IN A 192.168.122.4 srv-bind2 IN CNAME bind2 on applique les modifications\nnamed-checkzone adehu.com /etc/bind/adehu.com named-checkzone adehu.com.inverse /etc/bind/adehu.com.inverse systemctl restart bind9 pour le tester sur la machine host1\nnslookup adehu.com 192.168.122.4 ","date":"2023-09-27","permalink":"/posts/bind9-workshop/","section":"Posts","summary":"installation d\u0026rsquo;une infrastructure dns bind9 introduction # les deux premiers tp portent sur l\u0026rsquo;installation d\u0026rsquo;une infrastructure dns avec des serveurs bind9","title":"bind9 workshop"},{"content":"","date":"2023-09-01","permalink":"/tags/monitoring/","section":"Tags","summary":"","title":"monitoring"},{"content":"","date":"2023-09-01","permalink":"/tags/security/","section":"Tags","summary":"","title":"security"},{"content":" taking a tour \u0026amp; understanding\nvariety of security notions introduction # learning network security, i had to write a post related to it\nthis post aims to learn or clarify hosts \u0026amp; networks security notions/jargon, not covering kinds of threats or attacks\ni used simpler words than the ones found in my research to make it easier to read for non-native english speakers\ni am not an expert by any means, please let me know if i\u0026rsquo;ve said something wrong\nglossary # defining mandatory concepts related to the notions covered\nmalware # malwares are malicious piece of code or software designed to harm or hijack a device or its data by any means\npayload # payload is the part of a malware who responsible for the damages - data exfiltration, making a host unusable, etc.\nvulnerability # vulnerabilities refer to hardware, software or procedures weaknesses that could be exploited by a threat\nthreat # threats are malicious or negative potential events exploiting known or yet unknown vulnerabilities\nthe word threat actor comming from it refers to people behind a malicious incident\nrisk # risks qualifies the probability that a threat exploits a vulnerability causing a critical damage to the host or its neighbours\nrisk = threat * vulnerability * damage\nattack # attacks are the usage exploitation of a vulnerability by a threat actor\nclassification for those are seperated, e.g: human threat, viruses\u0026hellip;\nthreat model # threat modeling is the process of identifying potential vulnerabilities or security flaws, prioritising weaknesses to address or mitigiate to minimize the risks\nendpoint # endpoints are the farrest devices on a network comming from the outside, can be hosts or servers\nendpoint protection # are covered various protections for endpoints/hosts according to many types of threats \u0026amp; attacks\ni only wrote about relevant \u0026amp; still active protection solutions\nhardware side # fde # on the hardware side, full-disk encryption is a very good practice to preserve security \u0026amp; privacy for portable devices\nhaving Luks for all kinds of needs \u0026amp; BitLocker for windows OSs\nthe better \u0026amp; common way to do fde is by using the tpm trusted platform module chip to generate the encryption keys \u0026amp; keeping part of it to itself\nadditionnaly for luks, it uses a master key asked before the boot sequence using a passphrase hash to boot into the OS\ndlp # to minimise data loss (i.e. \u0026ldquo;availability\u0026rdquo; in production use), the threat model could implement a data loss prevention procedure\na usefull data loss model could be the 3-2-1 backup strategy\n3 copies of the data - (or more) 2 backups on different storage media - really helps 1 backup copy offsite - can be cloud, nas\u0026hellip; for personnal use, backuping on two different medias (e.g: a nas \u0026amp; a disk or cloud) can do the job, but please do not underestimate the value of backups in production use\nonce an host has been infected or is showing signs to, doing a quick \u0026amp; tested restoration is very usefull \u0026amp; saves time\nsoftware side # authorisation # authorisation can be associated to permissions\na good practice is to always let the minimal permissions to the users, restricting them to do only what they are intended to\nthat can be a part of the threat model: who can access which ressources\nin other words, when an user is compromised -\u0026gt; what can he access, so what became at risk?\ndisabling the root account is also a good practice for most hosts, prefering a sudoer or proper user permissions\nas always, good passwords are always a most \u0026amp; for the ssh protocol the usage of keys or certificates in highly recommended\nauthentication # using a login \u0026amp; a password cannot verify the identity of the person accessing a ressource behind the user\nsince then, human intervention has guaranteed the identity of the person accessing the resource\nback then, simple questions where asked to know if the intended person using the credentials was the one intended - e.g name of its dog, where did he was born, etc.\nthis authentication method was highly subjected to doxing\nnowadays, 2fa is used, living on the intended person\u0026rsquo;s phone or an dedicated hardware device (yubikey)\n2fa can take the form of push notifications (malicious ones can be injected), sms verifications (warning sim swapping attack method) or authenticators codes using the totp protocol\nmfa (multifactor authentication) can also be choose\nos/software side # epp # endpoint protection platform define the suite of technos or solutions used to protect endpoints\nng-av/edr # antivirus, next gen antivirus, endpoint detection \u0026amp; response\nare commonly used solutions to protect endpoints\nsources i found says different things about them, so i put ng-avs \u0026amp; edrs together, i wonder if their names are not just a marketing thing for the same solutions\n\u0026ldquo;legacy avs\u0026rdquo; are based in signature recognition to stop known malware file\nan individual hash could be generated for each file. standard avs compare them to a list of malicious files hash to know if the checked file is one of them or not to flag it\nit is only working against file-based attack \u0026amp; new or yet unknown malwares could not be discovered using this method\nvariations of a malware (malformed sinature trick) can also be done, so its bypass the hash check since it is not in the signature database\nngav use behaviour detection on top of the signature recognition, so if a software/program/service activity is suspicious -\u0026gt; the file or its activity can be put in quarantine or be stopped\nsome may introduce sandboxing \u0026amp; ai - machine learning although av \u0026amp; ngav are already well ressources hungry\nedr \u0026amp; ng-avs are very important security solutions since only the endpoint can see encrypted ongoing or incomming traffics (e.g. https traffic)\nbe aware that more than one av could lead to more ressource usage \u0026amp; them trying to cancel each other, since they are accessing same files \u0026amp; seeing each other activity\nnetwork solutions # network solutions are preferable so threats or attacks are stopped before reaching the endpoints\nfirewall # firewalling protects networks from unwanted traffic by setting a set of pre-programmed rules\nit can also provide a network segmentation, separating the lan local area network into smaller ones w/ their dedicated rules\nnot to compare w/ software firewalls who applies rules to an host only\nproxy # proxy servers could be an intermediate to access the internet in a lan\nvery usefull to reduce a network attack surface since all the traffic is going through it\nit can monitor traffic or gather metrics\nit also provide sort of firewalling since you are restricted by what the proxy permit you to access to\nit is also great for privacy since hosts are not directly exposed\nmany use of proxies can be found doing research\nreverse proxy # reverse proxies act the same as normal proxies but for incomming traffic\nendpoints are behind the reverse proxy so that all incomming connexions need to pass through the reverse proxy to access the hosts\nids \u0026amp; ips # intrusion detection systems \u0026amp; intrusion protection systems\nthe ids \u0026amp; the ips analyse real-time traffic for signature matching known attacks or suspicious behaviour\nthe difference between them is that ips can act as a hardware switch to cut a malicious traffic whereas the ids only raise alerts\nsoc # security operations center or isoc information security \u0026hellip;\nis the structure (people, room, screens, devices\u0026hellip;) where logs are gathered \u0026amp; correlated\npeople are present at full-time to maintain the soc since it is a very important protection mesure (the ciso chief information security officer, analysts, devops/secdevops person\u0026hellip;)\nthe soc integrate various solutions such as a siem or a soar for example\nthe soc team makes decisions to act on the feedback according to the logs activity\nndr/xdr # network detection \u0026amp; response and extended detection \u0026amp; response\nthe ndr monitor network layer 2-7 traffic, no agent on the endpoints\nxdr tend to gather more informations by installing agents on endpoints to gather data\nxdr seems to be more corporate solutions \u0026amp; focus on properitaty\nndr can be implemented on its own but a xdr may cause friction if it\u0026rsquo;s not the only protection system deployed\nsiem # security information \u0026amp; event manager\nis offenly used in a soc environment, it gather, centralize \u0026amp; organize all logs from various devices\nlogs gathered from the firewalls, network appliances, ids\u0026hellip; can be filtered by the siem since all their informations aren\u0026rsquo;t always relevant\nthe siem is: collecting, aggregating, identifying, categorising \u0026amp; analysing incidents or events\nthe siem needs continuous learning by the security team (this report is normal because, it is current that\u0026hellip;) or by ai (machine learning) to keep categorising the data well but that has more to do with a soar\nsoar # security orchestration, automation \u0026amp; response\ngo a step further than the siem, taking advantage of the automation\ndoing the same job as a siem but go a step futher by automating and orchestrating time-consuming manual tasks of the secops team, so they can speed up on real incident response time\n","date":"2023-09-01","permalink":"/posts/security-notions/","section":"Posts","summary":"taking a tour \u0026amp; understanding","title":"security notions"},{"content":" software management differences\n\u0026amp; package managers for windows software management # highlighting gaps \u0026amp; problems from the non software management in windows\ninstallation # to install a software in windows, an installer needs to be searched in a browser, downloaded (.exe, .msi\u0026hellip;) \u0026amp; executed to download the wanted software\nby downloading an installer externally, the chances to install a wrong software, install additional ones or a malware is increased\nupdates # software updates are individuals, each software must search for its update - background apps, when the computer starts etc.\nnor the Windows Update or the Microsoft Store will check for the external installed software updates\nuninstallation # most of the time, software can be found in the control panel or the apps section of the windows settings\nhowever, software installed in non common path are not listed alongside those\ndependencies installed to use them usually remain after uninstalling the software - how many programs in the control panel are not used\u0026hellip;\nsome improving # the Microsoft Store has improved the software management in windows\nthe software are trusted because approved \u0026amp; listed by Microsoft\nsoftware are searched \u0026amp; directly downloaded, no risks to download additional software or execute a malicious program online\nthe software installed from the Microsoft Store can be all updated at once, no background apps etc\nhowever, the ms store apps list doesn\u0026rsquo;t cover all the wanted users apps\nreal improvement # windows, maybe knowning how software are handled on linux, created their package manager\npackage managers are tools used to install \u0026amp; manage software \u0026amp; their packages\nlinux users use them to quickly install software, update their system, their software \u0026amp; packages whenever they want, and also uninstall software including unused dependencies\na package manager is a simpler \u0026amp; cleaner way to manage your system software \u0026amp; updates\npackages managers can also be used in companies to avoid installing software one by one on hundred PCs, run grouped updates, install specific ver. of a software \u0026amp; more\nwindows package managers # package managers can be found for different purposes\nhere are some of them, how to install \u0026amp; use them\nsmooth transition # to switch into a package manager easily, all installed apps can be found in the Control Pannel, under Programs, Uninstall Programs\ncertain other apps can be found in the Settings -\u0026gt; Applications\neither, this command can be launched in an admin. terminal to list installed apps - games not include, just the launchers\nGet-ItemProperty HKLM:\\Software\\Wow6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\* | Select-Object DisplayName, DisplayVersion, Publisher, InstallDate | Format-Table –AutoSiz export the list to a file\nGet-ItemProperty HKLM:\\Software\\Wow6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\* | Select-Object DisplayName, DisplayVersion, Publisher, InstallDate | Format-Table –AutoSize \u0026gt; C:\\programs.txt winget # winget is the windows package manager shipped with windows 11 - can be installed in windows 10 using a command\nadobe products \u0026amp; other microsoft trusted software can be installed quickly \u0026amp; securely through it\nwith vlc for example, instead of opening a web browser, searching vlc, downloading the installer, executing it, clicking next\u0026hellip;\nopen a Terminal or a Powershell \u0026amp; run\nwinget install vlc multiple software can be installed at once, to install gimp \u0026amp; vlc for example winget install gimp vlc\nwinget can search wanted packages, example with gimp\nwinget search gimp list installed packages\nwinget list uninstall one or more packages\nwinget uninstall vlc gimp upgrade one or all packages at once\nwinget upgrade --id Adobe.Acrobat.Reader.64-bit winget upgrade --all configuration can be exported if moving from a pc to an other\nwinget export packages.json winget import packages.json ninite # leaving the command line, ninite aims to install \u0026amp; update software all at once using a .exe\nvery usefull after a windows installation to download all your software at once if you didn\u0026rsquo;t have winget at first\nrunning it more than once will update the selected software\non their website, software to download can be choose, from that it will generate a .exe to install them\nselect software to install \u0026 \"Get Your Ninite\" chocolatey # most used package manager in windows, appeared before winget in 2011: chocolatey is a more open package manager\nmore packages are in chocolatey, they are moderated \u0026amp; doesn\u0026rsquo;t contain malware or bloatware\nchocolatey is more open, more widely used software are present than in winget, those who are not verified yet by windows\na single powershell command can install chocolatey, runned as admin\nSet-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString(\u0026#39;https://community.chocolatey.org/install.ps1\u0026#39;)) chocolatey has a strong \u0026amp; native gui called chocolateygui to avoid using commandline\nchoco install chocolateygui using it, all software can be upgraded at once, \u0026amp; its telling you an error if it can\u0026rsquo;t (standard installers don\u0026rsquo;t)\nthe commands are similar to winget with the choco command\ni personally use chocolatey when i got to be on windows host \u0026amp; find it more convenient to use, also for new users because of its native gui\nlist local installed software\nchoco list --local upgrade all packages\nchoco upgrade all and the ultimate command to remove a software with its dependencies if not use by other ones - those commands are the same\nchoco uninstall package --removedependencies choco uninstall package -x if an other software uses the removed one dependencies, chocolatey doesn\u0026rsquo;t uninstall them \u0026amp; tells you it didn\u0026rsquo;t\nbonus macos # the macos software management is different from the windows one\nalthough, homebrew has the same role as chocolatey does for windows\n","date":"2023-08-21","permalink":"/posts/win-pkgs-mngers/","section":"Posts","summary":"software management differences","title":"software in windows"},{"content":"","date":"2023-08-21","permalink":"/tags/windows/","section":"Tags","summary":"","title":"windows"},{"content":"","date":"2023-08-19","permalink":"/tags/cheat-sheet/","section":"Tags","summary":"","title":"cheat-sheet"},{"content":" introduction # here i expose my ssh usages \u0026amp; some advanced notions about it\ni\u0026rsquo;ll speak about the ssh protocol as the openssh implementation\ni\u0026rsquo;m tempted to write my articles in lower case only as i usually write so outside\nread this article like a cheat sheet\nfundamentals # secure shell - ssh, is a very versatile protocol but generally used to access a remote server command line securely\nencapsulate in tcp/ip use port tcp/22 by default use asymetric cryptography the first time accessing a remote ssh host, its public key fingerprint is prompted to know if you are accessing the wanted host - security reasons, MitM, asking you if you trust it or not\nif yes, the fingerprint is paste in ~/.ssh/known_hosts w/ the associate ip address \u0026amp; encryption protocol; its trusted by the local machine\nmodifications # on the ssh server side, connexions behaviour can be modified in /etc/ssh/sshd_config\n(sshd stands for ssh daemon)\nbasic ssh setup let you connect to a host entering an username \u0026amp; a password beside root\nif modifications is made, for the changes to take effect: the sshd service needs to be restarted\nsystemctl restart sshd good practices # change the ssh access port from the port 22\ncheck if the root login is disabled (yes by default)\nusing ssh keys or certificates (authentication) + username \u0026amp; password (authorisation)\nuse differents keys to access different servers\nuse ~/.ssh/config to easily manage keys \u0026amp; remote hosts\nuse a passphrase for your private keys\nkeys # the server has a public key that everyone can see, only you have the private key to connect to the server; public key -\u0026gt; the lock, private key -\u0026gt; the key\u0026hellip;\nprivate \u0026amp; public keys are generated simultaneously, various encryption algorithms could be choosen\nprivate keys default location is ~/.ssh - perfectly fine with it\nw/ openssl, this command brings forms to fill to create a public \u0026amp; private key pair\nssh-keygen # to generate keys to automate or create many at once w/out filling the forms:\n-C can be used to add a comment to a key\n-t to choose the encryption algorithm - rsa by default\n-b number of bytes, the more the better encryption\n-f the location, usefull when creating many keys at once\n-N \u0026quot;\u0026quot; specify a passphrase, replace what\u0026rsquo;s inside \u0026quot;\u0026quot;\npushing a public key to a remote host, after running the ssh-keygen command\nssh-copy-id -i path/to/key.pub username@remotehost or\ncat path/to/key.pub | ssh username@remotehost \u0026#34;mkdir -p ~/.ssh \u0026amp;\u0026amp; cat \u0026gt;\u0026gt; ~/.ssh/authorized_keys\u0026#34; passphrases # passphrases can be added to private ssh keys, preventing the usage of the key if stolen\nconfig file # ~/.ssh/config serve the ssh client to manage its remote hosts\nHost abitraryname Hostname remotehost User username Port sshport IdentityFile /path/to/privatekey after changes, no need to restart a service\nssh remotename certificates # works in the same way tls/ssl does for https\nused to scale ssh, usefull to create a limited time access\nafter creating a public \u0026amp; a private key (saw in keys), those can be signed w/ a Certificate Authority (CA) certificate\nssh-keygen -s hostca -I hostname.domain.tld -h -n hostname.domain.tld -V +52w key.pub -s hostca specify the file name of the CA private key\n-I hostname.domain.tld the certificate\u0026rsquo;s identity\n-h specify its an host certificate, not an user one\n-n hostname.domain.tld url to access the future host\n-V +52w certificates\u0026rsquo;s validity period (52 weeks)\n(a passphrase can be asked)\nkey-cert.pub should be generated\nto use it on a local machine, paste the the ca \u0026amp; the public key to the /etc/ssh folder on the remote host for example\nedit in the /etc/ssh/sshd_config file:\nHostCertificate /etc/ssh/key-cert.pub the remote host now present a certificate to anyone who connects\nto the client side, trust the ca in `$HOME/.ssh/know_hosts\n@cert-authority *.domain.tld ssh-rsa \u0026lt;hostca.pub content\u0026gt; file transfering # ways to transfer ressources to \u0026amp; from a remote host\nfrom a remote host # gather a file from a remote host\nscp username@remotehost:/remote/path/to/file . gather a folder from a remote host\nscp -r username@remotehost:/remote/path . synchronising files from a remote host using rsync\nrsync username@remotehost:/remote/path/to/file . rsync -r username@remotehost:/remote/path . to a remote host # send a file to a remote host\nscp filename username@remotehost:/remote/path send a folder to a remote host\nscp -r directoryname username@remotehost:/remote/path rsyncing\nrsync filename username@remote-host:/remote/path rsync -r directoryname username@remote-host:/remote/path mount a remote folder # mount a remote directory on local system w/ sshfs (ssh file system)\napt install -y sshfs # depends on your package manager mkdir mount-dir mount the remote directory in the created folder\nsshfs username@remote-host:/remote/path mount-dir changes in the mount-dir will also be made in remote-host:/remote/path\nto unmount it\numount mount-dir sftp # ssh file transfer protocol, or secure file transfer protocol\ncan be used with the sftp command to open a remote shell\nsftp username@remotehost can navigate with pwd, ls, cd \u0026amp; use get or put to gather or send ressources\nget filename put filename or\nget /path/to/remote/file /path/to/local/directory put /path/to/local/file /path/to/remote/directory a gui like filezilla for an easier transfer experience (gui) can be done\nx11 forwarding # use remote app gui on local host\nconfig remote server # run with root or sudoer\napt install -y xauth # to forward x11 packets, depends pkgs manager allowing x11 fowarding in /etc/ssh/sshd_config by removing #\n87#AllowAgentForwarding yes 88#AllowTcpForwarding yes 89#GatewayPorts no 90X11Forwarding yes 91#X11DisplayOffset 10 92#X11UseLocalhost yes 93#PermitTTY yes systemctl restart sshd ssh into it \u0026amp; try launching xapplications\ndepending on the remote server configuration, some extra work could be intended\nssh tunneling # to access specific ressources, vpns expose an entire network which cannot be relevant for security reasons\nssh tunneling encapsulate a layer 3-7 traffic between 2 hosts over ssh\nssh encryption is added to the communication - so that if an unsecured communication is used, it is encrypted\nit can also be used to bypass firewall restrictions by fowarding ports\nuncontrolled or unmonitored tunnels can be used as backdoors, for data exfiltration, bouncing attacks \u0026amp; more\nlocal fowarding # forward a port from a ssh client to a ssh server (launched from the ssh client)\nextremely usefull to access a remote service denyied by a firewall, it needs the remote host to be accessible with ssh\n%%{init: {'theme':'dark'}}%% graph LR a(local machine) b(firewall) c(remote host) a---b b--\u003ec let\u0026rsquo;s say you have a raspberry pi at 192.168.1.12 (remote host) w/ ssh access via the pi user\nit shosting a web server locally on its 5000 port \u0026amp; you want to access it locally through your machine\nssh -N -L 127.0.0.1:8080:127.0.0.1:5000 pi@192.168.1.12 ssh -N -L 8080:127.0.0.1:5000 pi@192.168.1.12 -N prevents from running an active ssh session\nall traffic (http requests) sent to localhost:8080 on local machine will be forwarded to raspberry pi\u0026rsquo;s 5000 port - responses sended back to you\nLocalForward variable can be edited in the config file to avoid putting it every connexion\nreverse ssh tunnels # also called remote ssh tunnels or ssh remote forwarding\nforward a port on a remote host (ssh server) to a port on a local machine (ssh client)\ninitialised by the remote server\nused to access a service hosted on a remote local network, from another network (or internet)\n%%{init: {'theme':'dark'}}%% graph LR a(remote sever) b(firewall) c(local machine) a---b b--\u003ec widely use to exploit systems on private networks\nlet\u0026rsquo;s say: the remote server is locally running a web server on its port 80, its local network address is 192.168.1.23\nthe local machine public ip address is 8.8.8.8 - google one \u0026amp; accessible w/ ssh\nssh -N -R localhost:8080:192.168.1.23:80 root@8.8.8.8 ssh -N -R 8080:192.168.1.23:80 root@8.8.8.8 the service running the remote server port 80 will be accessible by the local machine loopback address on port 8080\nprevent tunnels # PermitTunnel no can be changed in /etc/ssh/sshd_config to prevent tunnels creation\nssh bastions # can be called ssh jump servers, ssh proxies or ssh agent forwarding\na single server accessible via ssh from the internet to redirect ssh sessions to others hosts\nusefull to centralise \u0026amp; secure ssh connexions in a corporate network to reduce the \u0026ldquo;attack surface\u0026rdquo; to just one machine\nteleport is an opensource solution if not using openssh\nadvices # only the ssh port should be accessible for incomming connexions the ssh port is changed from 22 root user is disabled be very aware of the security implementations prevent users to use an ssh active session into the bastion itself other purposes # can be used to encapsulate data, doing other services than transporting ssh packets\ncan be used as a \u0026ldquo;vpn\u0026rdquo;, doing dynamic ssh port forwarding \u0026amp; encapsulate your data w/out exposing an entire network (ssh + socks5 proxy)\ncommand # ssh -J bastionaddress username@remotehost -J parameter can be avoided by configuring the ProxyJump permanently in config file\nparameters saw in config file can be added too\nHost arbitraryname ProxyJump bastionaddress creation of an ssh user that cannot ssh into the bastion itself, called bastionuser in /etc/ssh/sshd_config\ngive this user to anyone using the bastion\nMatch User bastionuser PermitTTY no X11Forwarding no PermitTunnel no GatewayPorts no ForceCommand /usr/sbin/nologin then modify the parameters\nssh -J bastionuser@bastionaddress username@remotehost for the ~/.ssh/config\nHost remotehost ProxyJump bastionuser@bastionaddress chrooting # change root (chroot) method changes appareant root directory for the running user to a root directory called a chrooting jail\nusefull when giving access to untrusted or unmonitored users\nssh support chrooting by restricting an ssh session to a directory\nyou can create a fancy one manually but it is very long, for each user\nrssh is a simpler way to do so\ncreate a new user with the /usr/bin/rssh shell\nuseradd -m -d /home/chrooteduser -s /usr/bin/rssh chrooteduser passwd chrooteduser or change existing user shell to /usr/bin/rssh\nusermod -s /usr/bin/rssh chrooteruser works for sftp \u0026amp; scp\ndnssec # ssh use tofu trust on first use, it trusts the ssh server the first time connecting to it\nso if someone tried to impersonate the remote host identity or the host change, its fingerprint will be different \u0026amp; a warning will pop up saying that\u0026rsquo;s not the wanted server\nif targetted by a man-in-the-middle attack the first connexion, you could be at risk using ssh connexion\ndnssec has many features to improve the standard \u0026amp; old dns protocol, one of which is: dns answers are not tampered\nit is possible that an attacker can hijack ssh connexions \u0026amp; create valid dnssec responses, but less likely\nuse ssh-keygen as usual w/ an url using dnssec \u0026amp; a . at its end to stop the domain for beeing repeated twice\nssh-keygen subdomain.domainwithdnssec.tld. then\nssh -o VerifyHostKeyDNS=yes subdomain.domainwithdnssec.tld. ","date":"2023-08-19","permalink":"/posts/ssh-cheat-sheet/","section":"Posts","summary":"introduction # here i expose my ssh usages \u0026amp; some advanced notions about it","title":"ssh explored"},{"content":" overviewing centreon it \u0026amp; getting fully hands-on introduction # The last article in this series will be devoted to discover \u0026amp; use Centreon IT.\nFeel free to correct me by email if i\u0026rsquo;ve said something wrong.\npresentation # Centreon IT is a french open-source based monitoring solution.\nIt is highly inspired by Nagios, since it was a Nagios frontend at its beginning.\nCentreon\u0026rsquo;s solutions has the same Nagios\u0026rsquo; plugins \u0026amp; hosts systems but can keep their hands on the plugins with their repository - where the community can freely publish them for Nagios.\nCentreon is a profit-oriented company who has a business model based on licensing the number of hosts monitored.\nThe free solution called Centreon IT-100 is licensed for 100 monitored hosts only - their Free Trial. Other differences with the commercial editions are listed in their comparison table.\nnamely # Informations on how Centreon IT works \u0026amp; its specific features.\norganisation # Centreon claims their solutions can be hosted on site, called OnPrem, or cloud-based, called Cloud.\nCentreon instances always works with a Central Server, called centreon-central used to configure monitoring, display \u0026amp; operate the collected data.\nTo monitor multiple sites, instances can be deployed \u0026amp; attached to the Central Server, the Remote Servers.\nMonitored data is gathered using Pollers, attached to the Central or a Remote Server.\nHere is what a Centreon OnPrem distributed architecture should looks like according to Centreon.\n%%{init: {'theme':'dark'}}%% graph TD central[Central Server] remote0[Remote Server] remote1[Remote Server] remote2[Remote Server] poller0((Poller)) poller1((Poller)) poller2((Poller)) poller3((Poller)) poller4((Poller)) poller5((Poller)) central---remote0 \u0026 remote1 \u0026 remote2 remote0---poller0 \u0026 poller1 remote1---poller2 \u0026 poller3 remote2---poller4 \u0026 poller5 The Centreon Cloud architecture does away with Remote Servers, as Pollers are connected to the Central Server via the cloud - using a vpn.\n%%{init: {'theme':'dark'}}%% graph TD central[Central Server] poller0((Poller)) poller1((Poller)) poller2((Poller)) central --- poller0 \u0026 poller1 \u0026 poller2 hosting # Centreon documentation guides to host onprem \u0026amp; cloud solutions on different supports.\nFor an overview, they give *.ovf \u0026amp; *.ova images for virtual box \u0026amp; vmware respectively.\nInstallations alongside gnu/linux distros is preferable for production use.\nThe documentation guides it for RHEL, Alma/Oracle/Rocky Linux since they are rhel based distros - (or \u0026ldquo;were\u0026rdquo; since rhel closed their source).\nLess attention is putted on Debian, the documentation is deprecated for it.\nIn the past - until ver. 21.10, they used to create *.iso images to install their solutions alongside centos.\nconnectors \u0026amp; plugins # Data collection performed by Centreon models called Monitoring Connectors which have Plugins assets.\nPlugins have the same function as Nagios ones.\nInstalled \u0026amp; used by pollers, they are sets of commands to monitor various kinds of metrics, on differents type of hosts regarding many protocols.\nPlugins \u0026amp; connectors are maintained in their centreon-plugins \u0026amp; centreon-connectors repositories, where it seems community can contribute.\nAlthough it\u0026rsquo;s opensource, a license is required to access the full Plugin Pack on their solutions.\ndeploying # Installing Centreon IT-100, doing a simple windows \u0026amp; linux hosts monitoring.\nrequirements # The infrastructure size depends on the number of hosts to monitor.\nCentreon recommends using lvm to manage their file systems - working fine without, but should be planned for production use.\nA stand-alone central server is used under 500 hosts. Pollers every 500 hosts are expected with a database server if more than 2'500 hosts.\nFor production use, it would be a good idea to think about scalability.\nSince there would be too much information to display (partitionning, specs, infrastructure), i let you refer to their infrastructure sizes charts.\ninfrastructure # An infrastructure similar to that used in the nagios article will be deployed.\nFollowing the requirements - partially since it is not for production use, a stand-alone Central server will be deployed with its poller.\nHere is what the used infrastructure looks like.\n%%{init: {'theme':'dark'}}%% graph TD subgraph lan[LAN] router{Router} switch[Switch] centreon(Centreon Central Server\n192.168.122.166) linux(Debian Host\n192.168.122.164) win(Windows Host\n192.168.122.251) mariadb[(MariaDB server)] poller((Poller)) end wan{WAN}---router router---switch switch---centreon switch---linux switch---win centreon-.-mariadb \u0026 poller installation # Centreon IT will be installed without license on Debian 11.\nI made an installation script available on Github.\nThis script installs Centreon IT from added Centreon\u0026rsquo;s apt repositories \u0026amp; install a secured mysql server through mariadb.\nTo execute it, run the following commands.\nmkdir testing \u0026amp;\u0026amp; cd testing wget https://raw.githubusercontent.com/xeylou/centreon-it-overview/main/debian-centreon-install.sh chmod +x debian-centreon-install.sh ./debian-centreon-install.sh Installation can be resumed going on the Centreon web interface http://192.168.122.166.\n(cannot highlight forms natively, so i specify the changes, otherwise i just do next, install or finish)\nMore dependencies than the ones loaded could be presented as Not loaded for debugging (if not using the script).\nCreation of an admin account for the Centreon interface.\nConnexion to the db server. The root password was asked \u0026amp; created by the script at the end.\nUsed localhost (so 127.0.0.1 or ::1) for the db server ip address, since its hosted on the same host as the future centreon central server.\nCreation of a db user to perform data querries - for security purposes, not doign them with an admin one.\nLogin created step 5 Admin information.\nThis is the after-loggin page.\nAfter the installation, the Central server poller is not working.\nAdditionnal steps are required to start monitoring.\nGo to the poller section to see it.\nNeed to click on Export configuration.\nSelect the Central poller.\nCheck Move Export File.\nThen Export.\nAfter that, run the following commands, keep their order without modifying them.\nsystemctl restart cbd centengine systemctl restart gorgoned systemctl start snmptrapd centreontrapd systemctl start snmpd Then the poller starts working.\n(the red circle at top left, to the right of Pollers logo disappears later, see screenshots below)\nsnmp plugins # Centreon recommends using their snmp implementation plugins to gather metrics - cpu load, memory usage etc.\nUsage of the snmp protocol garantees the monitoring to work as intended since the protocol is universal - rather than installing an agent.\nPlugins can be added using the web interface or by using the system package manager (dnf for rhel based distros \u0026amp; apt for the debian family).\nHere is the installation of the needed snmp plugins using the web interface.\nAdding the linux snmp plugin clicking +.\nBase Pack is an expected dependency that will be installed choosing Apply.\nDoing the same for windows snmp plugin, no more dependency needed.\nResult.\nOn wanted monitored hosts, snmp must be configured and working.\nlinux host # Note I\u0026rsquo;ve explained what were done with snmp rather than just throwing you my script as you may need this explainations to monitor other devices like switches or routers. (which doesn\u0026rsquo;t mean i haven\u0026rsquo;t made one) For our needs, according to the debian snmp page, a repo needs to be added to /etc/apt/source.list.\n1# deb cdrom:[Debian GNU/Linux 11.7.0 _Bullseye_ - Official amd64 NETINST 20230429-11:49]/ bullseye main 2 3#deb cdrom:[Debian GNU/Linux 11.7.0 _Bullseye_ - Official amd64 NETINST 20230429-11:49]/ bullseye main 4 5deb http://deb.debian.org/debian/ bullseye main 6deb-src http://deb.debian.org/debian/ bullseye main 7 8deb http://security.debian.org/debian-security bullseye-security main 9deb-src http://security.debian.org/debian-security bullseye-security main 10 11# bullseye-updates, to get updates before a point release is made; 12# see https://www.debian.org/doc/manuals/debian-reference/ch02.en.html#_updates_and_backports 13deb http://deb.debian.org/debian/ bullseye-updates main 14deb-src http://deb.debian.org/debian/ bullseye-updates main 15 16# This system was installed using small removable media 17# (e.g. netinst, live or single CD). The matching \u0026#34;deb cdrom\u0026#34; 18# entries were disabled at the end of the installation process. 19# For information about how to configure apt package sources, 20# see the sources.list(5) manual. 21 22# snmp needs 23deb http://httpredir.debian.org/debian bullseye contrib non-free After that, the needed packages can be installed.\napt update apt install -y snmp snmptrapd snmp-mibs-downloader Checking if the snmp service is running properly.\nsystemctl status snmpd If not, it needs to be started.\nsystemctl start snmpd Before making changes to the snmp daemon configuration file /etc/snmp/snmpd.conf, a backup is always welcome.\ncp /etc/snmp/snmpd.conf{,.old} The snmp protocol will listen for connections on all interfaces on port 161 udp for ipv4 \u0026amp; ipv6.\nSNMP will wait for a specific ip address under a certain community called public here.\nModifications are done in /etc/snmp/snmpd.conf.\n41# agentaddress: The IP address and port number that the agent will listen on. 42# By default the agent listens to any and all traffic from any 43# interface on the default SNMP port (161). This allows you to 44# specify which address, interface, transport type and port(s) that you 45# want the agent to listen on. Multiple definitions of this token 46# are concatenated together (using \u0026#39;:\u0026#39;s). 47# arguments: [transport:]port[@interface/address],... 48 49agentaddress udp:0.0.0.0:161,udp6:[::]:161 67# rocommunity: a SNMPv1/SNMPv2c read-only access community name 68# arguments: community [default|hostname|network/bits] [oid | -V view] 69 70# Read-only access to everyone to the systemonly view 71# rocommunity public default -V systemonly 72# rocommunity6 public default -V systemonly 73rocommunity public 192.168.122.166 After that, the snmp service needs to be restarted.\nsystemctl restart snmpd This command can be run from the Centreon Central Server to check if the configuration is working.\nsnmpwalk -v2c 192.168.122.164 -c public If it does, a lot of text will be displayed rather than this output: Timeout: No Response from 192.168.122.164.\n(if you are working with snmp layer: this command retrieves records from mib by going through each oid running automatic getnext requests, so you don\u0026rsquo;t need a command for each oid or node, on snmp ver. 2c asked with \u0026ldquo;public\u0026rdquo; community)\nwindows host # The windows host is a windows server.\nThe snmp protocol will be enabled on it, authorizing only the centron-central to communicate via a community named public.\nOn the Server Manager window.\n(here i can nicely highlight the forms)\nSelect the hostname of the windows server.\nNo need to add anything, just go Next.\nSearch for the SNMP Service \u0026amp; enable SNMP WMI Provider.\nRight after that go Next.\nThe snmp service needs to be configured in the Server Manager window.\nFind the SNMP Service among the services.\nAdd a community, here public, the same as the one configured on the debian host.\nRead Only is preferable because nothing has to be changed, just the metrics to be gathered.\nThe Centreon server needs to be trusted by entering its ip address.\nLet\u0026rsquo;s click Ok (does Apply \u0026amp; quit).\nThen Restart the service to make the changes take effect.\nThe same command used to check the connectivity of the debian host can be used for the windows one, changing the ip address.\nsnmpwalk -v2c 192.168.122.251 -c public adding hosts # Before adding the hosts to Centreon, it would be pleasant to check their snmp connectivity.\nsnmpwalk -v2c 192.168.122.251 -c public snmpwalk -v2c 192.168.122.164 -c public If the Centreon server can reach them, they can be added to its interface.\nGo to the Hosts configuration.\nClick on Add.\nFilling with the informations for debian host \u0026amp; some arbitraty ones.\nSave.\n(the Default equals Yes for the two cases)\nDoing the same for the windows host informations.\nThe host are added, should looks like so.\nThe pollers need to actualize their configuration files to starts monitoring the hosts.\n(note the red Yes on Conf Changed) Export the configuration in a file for pollers but this time also restart them.\nTo see the hosts \u0026amp; their services status.\nAfter 5 minutes or a Force check.\nIncomming ping (echo requests) are blocked by the windows firewall by default in windows client \u0026amp; server.\nAlthough it is marked as critical, it doesn\u0026rsquo;t shows up like so in the services section at the top left\u0026hellip;\nadding services # More services can be monitored by adding them into the centreon interface.\nClick on Add. Services to monitor can be added according to what plugins are installed in the Centreon server.\nThe sheet with an eye is a small documentation on the command arguments, parameters, etc.\nThe Default options are Yes in the three cases.\nAn then export the configuration \u0026amp; restart the pollers to make changes take effect, like did at the end of adding hosts.\n(to avoid putting a third time the captures how to do it)\ndebugging # Passives checks commands can be seen, helping a lot for debugging.\nIt can also helps for active monitoring without dealing with the Centreon interface.\nHere is how to do so with the swap services.\nThe syntax is the same for the windows \u0026amp; the linux smp plugins except the --plugin option.\nThe services commands syntax are the same, the --mode option change for cpu, load, memory, uptime, etc.\nclose # Here are some commands that helped me (hope can help you) for debugging - apart from connectivity debugging, because i had to debug a lot compared to itop or nagios\nsystemctl status cbd systemctl status gorgoned systemctl status centreon systemctl status centengine systemctl status snmptrapd (btw the centreon service has never been active\u0026hellip;)\nThere are many more services to know \u0026amp; check to understand a problem at the beginning.\nIn Nagios, for the same kind of interface (checking hosts services) you just have the nagios service to check for errors.\nFor centreon, the gathering, the processing, the display parts \u0026amp; more are seperate ones.\nIt\u0026rsquo;s better seperating parts of codes for debugging or reliability, but having a single service that reports all problems can be pleasant (or just not so many services).\nI got hard times to find were a problem could come from sometimes, since the numbers of potential services problem was huge.\nI also understand that centreon as more features (graphs etc.) than nagios base, not xi.\nCentreon uses nagios plugins, in the same directory as nagios does by default\u0026hellip;\nNagios has a page dedicated to CVEs to prove their concern \u0026amp; patches. There may be one, but i haven\u0026rsquo;t found a \u0026ldquo;security concern\u0026rdquo; or issues page\u0026quot; for Centreon.\nThat\u0026rsquo;s disappointing since monitoring systems needs to be very aware of their security.\nCentreon systems were also targetted by russian attackers ( article 1, article 2).\nIt is a very good idea to display the command used to check a service, i think i hadn\u0026rsquo;t seen that in nagios.\n","date":"2023-08-12","permalink":"/posts/centreon-it-overview/","section":"Posts","summary":"overviewing centreon it \u0026amp; getting fully hands-on introduction # The last article in this series will be devoted to discover \u0026amp; use Centreon IT.","title":"centreon it overview"},{"content":"","date":"2023-08-12","permalink":"/series/exploring-monitoring-solutions/","section":"Series","summary":"","title":"Exploring Monitoring Solutions"},{"content":"","date":"2023-08-12","permalink":"/tags/open-source/","section":"Tags","summary":"","title":"open-source"},{"content":"","date":"2023-08-12","permalink":"/series/","section":"Series","summary":"","title":"Series"},{"content":" combodo itop tour \u0026amp; creating a living\nit service delivery infrastructure introduction # As with Nagios, i dived into Combodo iTop solution.\nEven though it is not a host monitoring solution, it can be a part of a monitoring infrastructure.\nI had harder time getting into it due to the notions to lean \u0026amp; to consider, inside \u0026amp; outside itop to use it properly.\nSo once again, i\u0026rsquo;d be very grateful if you\u0026rsquo;d consider correcting me if i said someting wrong.\nglossary # Defining mandatory acronyms for this post.\nITSM - IT Service Management\nType of tool usually used by companies to organise \u0026amp; deliver their IT services to their departments or to other companies. They can integrate monitoring tools or a help desk ticketing system for example.\nCMDB - Configuration Management Database\nTerm to define a database used to store \u0026amp; organise the hardware items \u0026amp; the software assets of a company or someone.\nITIL - Information Technology Infrastructure Library\nSet of relevant IT practices describing processes, procedures or actions for IT related operations like system administration or itsm management.\npresentation # Combodo is a 13-year-old french company who created itop, an open source, itil based, itsm \u0026amp; cmdb solution.\nThey are a profit based company, they created 2 non-free versions of itop for business purposes: essentials \u0026amp; professional/enterprise.\nThey also provide free \u0026amp; non-free external software to enhance itop utilisation like a front-end customiser or a network related manager; as weel as consultants.\nitop is typically used by the IT department of a company to organise services \u0026amp; implement a help desk ticketing system to the other departments.\nIt is also used by companies to deliver IT services to other companies as a service provider.\nunderstandings # Reviewing my understanding of itop\u0026rsquo;s main features.\nfundamentals # itop is based on apache, php, graphviz \u0026amp; mysql. However, it can run on nginx instead of apache with extra work.\nThe documentation is made for anyone who is susceptible to use itop.\ncmdb # The cmdb is the core of itop.\nThe cmd works with Objects, which are groups of Instances sharing the same patern.\n(considering the \u0026ldquo;Persons\u0026rdquo; object, each instance of this object would have the same patern: a name, a surname, an age etc.)\nThe cmdb can receive a populated *.csv file to create multiples instances of an object at once. (instead of entering one by one every member of a company for example)\nitop can receive custom objects but their implementation is not guided. The default ones are created without instances.\nObjects \u0026amp; instances are stored in the MySQL database.\nitsm # The itsm is integrated with the ticket management system \u0026amp; will be described using the itil way.\nWhen installing, itop proposes two ways to implement it: to deliver services to departments or to other companies; saw at the end of the presentation.\nThe itsm provides two types of tickets for end users: Users requests \u0026amp; Incidents.\nMandatory objects are needed to use them: Services, Contracts \u0026amp; SLAs.\nHere are their purposes \u0026amp; how they are related.\nServices\nAre defining what is provided by the service provider (IT department or company). Called to generate incidents or to supply users requests. Providers contracts are required.\nContracts\nSplited in Customer \u0026amp; Provider contracts. Customer one defines service(s) provided to/pucharsed by the customer + the SLAs. Provider one links internal ressources (CIs) used for the service(s) provided.\nSLTs - Service Level Target\nDefine metrics agreements between customers \u0026amp; providers. Two by default: TTO - Time To Own: time to take a ticket into account \u0026amp; TTR - Time To Resolve a ticket after creating.\nSLAs - Service Level Agreement\nGroup of SLTs defining the agreement between a provider \u0026amp; a customer for a given set of services.\nWhen a customer creates a ticket, it can select the service amongst the list of services defined for this customer.\nTickets deadlines are computed depending on the SLA signed with the customer.\ndefault objects # Native objects in itop are created during the installation process.\nThey should be used because related to itop principles.\nThe mandatory objects are covered here, many more can be used \u0026amp; discovered exploring itop.\nOrganizations\nCan be used for two purposes: name the different departments of a company when itop is used to deliver IT services within a company, or name the different companies a company is delivering IT services to.\nLocations\nAre used to group objects by geography - servers, organisations etc. A hierachy can be applied, locations can be linked to parents locations (example: inside the company A, there is room A \u0026amp; room B in which have differents servers in racks A \u0026amp; racks B)\nPersons\nDefine the persons contacts \u0026amp; responsabilities regarding the IT services delivered. Can be deployed using Profiles to quickly assign permissions (to the members of a department or a company).\nTeams\nUsefull to define permissions easier - all the HR \u0026amp; finance teams can access to\u0026hellip; -. Can also help the customer to communicate using the ticketing system.\nCIs - Configuration Items\nDescribe hardware devices: racks, pdus, network devices, servers, personal computers, hypervisors, vms etc. Templates are available for a large type of CIs.\nSoftware Installed\nPresent to easily index software installed on devices, licences \u0026amp; so on.\nServices\nObject used to define what actions or access is delivered as a service to a customer. Can be subcategorised - service A contains sub-service B \u0026amp; sub-service C.\nobjects agencement # Objects are related to each others by different means.\nI made graphs to show the links between them, or tried to.\nGraphs are generated using the following rules:\nRectangles are highest objects. Rounded objects are those receiving links. Text in lowercaps are instructions, uppercaps are objects name. Persons integrate Teams according to their Roles.\ngraph LR A[Persons] --\u003e|Roles| B(Teams) Teams belongs to Organizations.\ngraph LR A[Teams] --\u003e|belongs to| B(Organizations) Organizations are linked to Locations.\ngraph LR A[Organizations] --\u003e|are located| B(Locations) Regarding to only these objects, links can be created.\n(Persons -\u0026gt; Teams -\u0026gt; Organizations -\u0026gt; Locations)\nBefore doing that, there are links between objects covered in default objects.\nOrganizations are owning CIs. CIs are exposed to Services \u0026amp; are ruled by Provider Contracts. They can be related to Documents \u0026amp; appear in Tickets.\ngraph LR B[Organizations] --\u003e|owning| A(CIs) A --\u003e|exposed to| C(Services) D[Provider Contracts] --\u003e|rule| A A --\u003e|appear in| E(Tickets) A --\u003e|related to| F(Documents) Relations for Documents.\ngraph LR C[Organizations] --\u003e|owning| A(Documents) A --\u003e|used for| D(Contracts) D --\u003e|defining| A A --\u003e|give informations| F(CIs) A --\u003e|linked to| E(Services) All objects have relations to others at some point by different ways.\nIn addition to this, objects\u0026rsquo; instances have their own properties changing the relations between objects according to their needs.\nIt would be meaningless to create decent relations graphs for all objects, since their dependencies \u0026amp; relationships are to massive \u0026amp; could change each instance.\nDo not refer to this graph. Please read above. graph LR subgraph iTop Company View A[Persons] --\u003e|Roles| B(Teams) B --\u003e|parts of| C(Organizations) C --\u003e|are located| I(Locations) C --\u003e|owning| D(CIs) D --\u003e|related to| E D --\u003e|exposed to| G(Services) H(Provider Contracts) --\u003e|rule| D D --\u003e|appear in| F C --\u003e|owning| E(Documents) E --\u003e|used for| H H --\u003e|defining| E E --\u003e|linked to| G E --\u003e|give informations| D A --\u003e|see activity| D A --\u003e|attached to| F(Tickets) J[Other Objects] --\u003e|give properties| D J --\u003e|structure| E end Even though this graph seems valid for the most part, itop has many more objects than the ones covered. Links between them should be discovered \u0026amp; created using the frontend.\nimplementation # This sections will implement itop following a companies charts \u0026amp; an arbitrary infrastructure.\ncompanies charts # itop will be used by two companies: Company A which is the service provider \u0026amp; Company B who use their services.\nHere is the Company A agency graph.\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%% flowchart TD subgraph z[Company A Chart - Service Provider] subgraph m[CEO] a[Person A] end subgraph h[Executive Assistant] b[Person B] end subgraph i[Technical Manager] c[Person C] end subgraph j[Network \u0026 Sysadmins] d[Person D] e[Person E] end subgraph k[Work-Study Students] f[Person F] g[Person G] end end m---h m---i i---j i---k style z fill:#fff,stroke:#fff,stroke-width:4px Here is the Company B one.\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%% flowchart TD subgraph z[Company B Chart - Consumer] subgraph a[CEO] b[Person H] end subgraph c[Technical Manager] d[Person I] end subgraph e[Sales Manager] f[Person J] end subgraph g[Head of Logistics] h[Person K] end subgraph i[\"Manufacturing Manager\"] j[Person M] end subgraph k[Assistant] m[Person N] end end a---c a---e c---g c---i e---k style z fill:#fff,stroke:#fff,stroke-width:4px All persons in the two companies will have access to an itop interface (in reality it is not necessary).\nrequirements # Here is the itop hardware recommendations from their documentation.\nActivity Recommendations Tickets/monthUsersCIs\u0026lt;200\u0026lt;20\u0026lt;50k\u0026lt;5k\u0026lt;50\u0026lt;200k\u0026gt;5k\u0026gt;50\u0026gt;200k ServersCPUMemoryMySQL DB sizeAll-in-one2vCPU4Gb10GbWeb+MySQL4vCPU8Gb20GbWeb+MySQL8vCPU16Gb50Gb infrastructure # There is 13 people who will potentially use itop in the two companies combined (\u0026lt; 50). The number of CIs will be under 50'000 \u0026amp; the tickets/month under 200.\nThe all-in-one server will be chose with itop \u0026amp; a MySQL server installed.\nNote For a production use, looking for expandability by choosing the seperate solutions would be a better choice. Here is the network infrastructure that will be used.\ngraph TD subgraph company-b[Company B Network] router-b{Router} switch-b[Network Switch] consumer-pc(Consumer Device) apache-b(Apache Server) end subgraph company-a[Company A Network] router-a{Router} switch-a[Network Switch] itop-server(Debian Machine\n2vCPU 4GB) db-server[(MySQL DB\n10GB)] itop(itop Community) apache-a(Apache Server) end wan{WAN} --- router-a \u0026 router-b router-a ---|192.168.122.0/24| switch-a switch-a ---|192.168.122.212| itop-server itop-server -.- db-server \u0026 itop switch-a ---|192.168.122.111| apache-a router-b ---|192.168.1.0/24| switch-b switch-b ---|192.168.1.1| consumer-pc switch-b ---|192.168.1.2| apache-b The Company A is providing an apache web server from their LAN as a service \u0026amp; monitor an other one from the Company B LAN.\ninstallations # I made an installation scripts for itop community \u0026amp; for a mysql server according to itop requirements.\n(yes, i could saved a lot of time not doing this, but foss)\nBoth scripts are interactive \u0026amp; made for debian - tested on debian 11 \u0026amp; 12, source code is on Github.\nThe itop server installation can be done running the following commands.\nmkdir itop_install \u0026amp;\u0026amp; cd itop_install wget https://raw.githubusercontent.com/xeylou/itop-tour/main/debian-itop-install.sh chmod +x debian-itop-install.sh ./debian-itop-install.sh Here to install the mysql server.\nmkdir mysql_install \u0026amp;\u0026amp; cd mysql_install wget https://raw.githubusercontent.com/xeylou/itop-tour/main/debian-mysql-install.sh chmod +x debian-mysql-install.sh ./debian-mysql-install.sh An external mysql database can be used without this installation script, an full privilieged user for this database is needed to use itop.\nThe installation can be resumed at http://192.168.122.212.\n(highlighted forms are clicked/changed values)\nThe warning says the used php version (latest) is not tested for this itop version by Combodo. (not appening with debian 11 because its repositories has an older php version) The Server Name is localhost because the itop instance \u0026amp; the mysql server are on the same host - can be replaced by the ip address of the external mysql server if using the seperate solution.\nThe Login \u0026amp; the Password was created during the debian-mysql-install.sh script process - asked at the beginning -. The database name found was also created during the installation process. Person C will have admin privilieges for this itop instance, since it is the Technical Manager. (can add more admins after)\nThe Language set is for this user only. Here the Default Language for all users can be changed. Can also be changed by individual users after deploying. Since the Company A acts as a service provider, the second option is chose. The first option should be kept if delivering IT services to company departements. Simple Ticket Management can be chose to get rid of SLTs \u0026amp; SLAs. The Customer Portal is the itop interface but reagenced for users tickets. If not chose, tickets should be created using command-lines method or the rest api. cmdb confirguration # The cmdb (organizations, persons, teams etc.) needs to be configured first.\nDepending on the company/ies \u0026amp; the infrastructure/s sizes, it could take some time to populate.\nExporting \u0026amp; importing csv files is a great option to configure it quickly. Here is a video from itop explaining how to do so (i still think putting mine will be worse).\nSynchronizing csv files (itop server \u0026amp; an editor side) can also be done to avoid entering each modification manually, scheduling this task to. ELDAP \u0026amp; AD services can also be used instead of this method.\nManual objects implementation \u0026amp; modification can also be done. A rest api is also present for external use cases.\nitsm overview # The itsm is following the cmdb configuration: users created, teams, organizations, services, contracts etc.\nExternal User profile for the iTop User object have a dashboard to create requests according to purchased services.\nThe user can change his Phone number, Location according to his company\u0026rsquo;s locations in the cmdb, the language to use or his profile picture.\nIt can also rename his function inside the company or change his password.\nWhen entering in New request, according to default objects, the services can be defined in sub-services to help the end user.\nThe provider has the itop dashboard (administrators like person c or other profiles) to interract with created tickets.\nTo avoid putting a gigantic amount of screenshots to show how the itsm works, here is itop video for that (better than the ones i made i think\u0026hellip;).\nA designer is available to custom the itsm interfaces.\nmonitoring # Once the cmdb is configured, links can be done between hardware \u0026amp; Application Services for the end users.\nThey are created using Contracts (Customer \u0026amp; Provider) with SLAs etc.\nSince itop is an itsm \u0026amp; cmdb solution, it doesn\u0026rsquo;t have a proper monitoring system.\nHowever, itop can integrate nagios for incident management (creating tickets).\nclose # It required a lot of time \u0026amp; effort to make my hands on, it\u0026rsquo;s not incredibly difficult - depends on what you usually do - but demanding. (compare to the nagios experience i have)\nTo keep their customers\u0026rsquo; time, they do bootcamps for 140$/h \u0026amp; have paid consultants.\nFor a production or business use, customers may pay for the professional or business itop solutions with consultants to help them integrating itop \u0026amp; keep a lot of time.\nI think one or more IT guys are needed to implement, maintain \u0026amp; using it (expecially with oql querries \u0026amp; various technos not covered).\nI saw on forums itop could implement customers\u0026rsquo; itsm for their need, but the discussion stopped here.\nI also like their blog.\nI am happy that i have found a way to understand itop \u0026amp; the surroundings properly \u0026amp; alone in a week, i hope so.\n","date":"2023-08-05","permalink":"/posts/itop-tour/","section":"Posts","summary":"combodo itop tour \u0026amp; creating a living","title":"combodo itop tour"},{"content":" understanding Nagios principles \u0026amp; deploying\na monitoring infrastructure using custom scripts introduction # For my work-study, i immersed myself in understanding Nagios.\nHere i expose what i\u0026rsquo;ve learned \u0026amp; what i\u0026rsquo;ve done with it.\nI\u0026rsquo;d be extremely grateful if you\u0026rsquo;d consider correcting me if i said something wrong.\nThis article mainly talks about Nagios as the Nagios Core solution.\npresentation # Nagios Core is an open source, widely used monitoring tool for hosts, applications \u0026amp; services.\nThe company behind Nagios, Nagios Enterprises, afford to make Nagios Core free \u0026amp; open source by their financing policy.\nThey provide non-free solutions to make the Nagios Core utilisation simplified, such as a more sophisticated dashboard - Nagios XI, or a better network implementation - Nagios Network Analyzer.\nThose solutions are improvers for Nagios Core, highly prefered for production use but not essential to use Nagios Core.\nside notes # Nagios Core source code can be found on Github, it is written in C language.\nYou may also consider, regarding your deontology or your use case, using your own metrics collector to serve them into a dashboard - using Prometheus \u0026amp; Grafana for examples.\nnagios principles # Covering the basics of Nagios Core according to monitoring windows \u0026amp; linux hosts with their services.\nfundamentals # Nagios Core need to be installed on a host, bare metal or in a vm - no official docker image available.\nTo monitor hosts, the Nagios server will execute a sequence of commands at a sheduled interval \u0026amp; will define the state of the monitored host/service according to the output of the sequence.\nThis series of checks can be customised according to what service you want to monitor.\nA simple \u0026amp; in use example can be the default HOST STATUS check by Nagios: the Nagios server send an echo request to the host - ping command. If it receive an echo reply back -\u0026gt; HOST STATUS: UP, else -\u0026gt; HOST STATUS: DOWN.\nApart from well-known protocols, to monitor the largest amount of services, Nagios lets its community post their own Projects.\nSince then, the community created \u0026amp; shared their free plugins \u0026amp; add-ons to monitor their needed services on Nagios - all in their Nagios Exchange platform.\nplugins # The commands used to monitor services are called plugins.\nPlugins are located in /usr/local/nagios/libexec/ with their name starting with check_*.\nThese plugins can be used as executable files to quickly check the status of services. Those actions are parts of \u0026ldquo;active monitoring\u0026rdquo;, which are usefull during pre-production tests.\nExample of an active check with check_http plugin.\n/usr/local/nagios/libexec/check_http -h display the help page\nfor the check_http plugin\nFollowing the check_http help page, this check can be executed on a host to check its http response.\n/usr/local/nagios/libexec/check_http -H 192.168.122.15 HTTP OK: HTTP/1.1 200 OK - 10975 bytes in 0.002 second response time |time=0.001620s;;;0.000000 size=10975B;;;0\nadd-ons # Plugins only monitor external metrics.\nTo monitor internal ones like system utilisation (cpu load, ram utilisation, disk usage etc.), Nagios use what they call add-ons.\nAdd-ons are splited software, an agent part is installed on the monitored host waiting for a gathering query \u0026amp; an executable file is on the nagios server to communicate with the agent api.\nThose add-ons often use tokens or passwords to verify the authenticity of the nagios server.\nFrom the Nagios server side, the add-ons will be used as executable files like plugins are.\nnagios configuration files # Nagios *.cfg configuration files are located in /usr/local/nagios/etc/.\n. ├── cgi.cfg ├── htpasswd.users ├── nagios.cfg ├── ressource.cfg └── objects ├── commands.cfg ├── contacts.cfg ├── localhost.cfg ├── printer.cfg ├── switch.cfg ├── templates.cfg ├── timeperiodes.cfg └── windows.cfg Since they are well documented inside \u0026amp; on the web, i\u0026rsquo;ll just outline their purpose.\nThe nagios.cfg is the main Nagios configuration file. It contains informations such as log files location - can be changed, locations of directories or individual hosts configuration files, services update interval \u0026amp; more.\nA standard htpasswd.users is created in the installation process \u0026amp; define the Nagios users passwords.\nCGIs check their cgi.cfg configuration file to gather user \u0026amp; groups permissions \u0026amp; rights. It also contains the path for Nagios frontend files.\nressource.cfg define macros used in hosts configuration files for sensitive informations. Also provides plugins paths - handy for moving plugins or adding custom ones.\n(example of \u0026ldquo;sensitive informations\u0026rdquo;: to monitor non public metrics about a database, it is needed at some point to log into using a username \u0026amp; a password)\nThe configuration files inside the objects directory are used to define commands, contacts, hosts, services etc. (more on that in hosts configuration files)\nhosts configuration files # Nagios monitor hosts by scheduling plugins tasks or calling add-ons and reporting the results on a control panel.\nTo define what checks should be made on which host, Nagios use Object Configuration Files.\nThese are *.cfg configuration files in which you define the host informations \u0026amp; the check_ commands that should be used.\nIt is recommended to create directories to manage your kinds of hosts - create a folder with all the *.cfg files for windows clients, linux servers etc.\nOtherwise, configuration files can be manually added to the nagios.cfg like the localhost.cfg by default.\ndeployment # Demonstration of what is said in how nagios works.\nDeploying an infrastructure based on the system monitoring of a Windows Host (server or client) \u0026amp; a Debian Host.\nnetwork plan # N a g i o s S e 1 r 9 v 2 e . r 1 6 8 . 1 2 2 . 2 0 3 N e W t i w n o d r o k w s S w H i 1 o t 9 s c 2 t h . 1 6 8 . 1 2 2 . 5 3 D e b i a n H 1 o 9 s 2 t . 1 6 8 . 1 2 2 . 1 6 5 windows host # Add-ons are needed to monitor hosts system activity.\nA lot of agents are available for windows \u0026amp; linux hosts. Nagios Cross-Platform Agent (NCPA) will be used because it is still recently maintained - by Nagios Enterprise.\n(note: for community maintained one, NSclient++ for windows \u0026amp; linux seems to be a good choice)\nTo install NCPA, need to start by downloading \u0026amp; executing the agent installer on the host.\nDownload the latest NCPA agent installer Here are the simple following steps for the install.\n(highlighted forms are clicked/changed values)\nBind IP has a default value of 0.0.0.0 to accept every ip address who request metrics - replaced it by the Nagios Server ip address.\nPort \u0026amp; Token can be changed.\ndebian host # NCPA will also be used for the debian host so that the check commands syntax will be the same for both host.\nI made an installation script for the debian agent, source code is on Github for debian 11 \u0026amp; 12.\nmkdir testing \u0026amp;\u0026amp; cd testing wget https://raw.githubusercontent.com/xeylou/nagios-introduction/main/debian-ncpa-install.sh chmod +x debian-ncpa-install.sh ./debian-ncpa-install.sh By using it, it will ask you the Nagios Server ip address \u0026amp; a custom token so that only it can gather metrics.\nChanges are made by changing the allowed_hosts \u0026amp; community_string variables in /usr/local/ncpa/etc/ncpa.cfg.\nFor other linux distributions than debian, the ncpa download page can be usefull.\nThe default 5693 port is used to transfer metrics.\nnagios server # The Nagios Server is in my case a Debian machine that host Nagios Core \u0026amp; the Nagios Plugins.\nI made an installation script for those by compiling code from source - tested on debian 11 \u0026amp; 12.\nmkdir testing \u0026amp;\u0026amp; cd testing wget https://raw.githubusercontent.com/xeylou/nagios-introduction/main/debian-nagios-install.sh chmod +x debian-nagios-install.sh ./debian-nagios-install.sh Nagios web interface can be reach at http://192.168.122.203/nagios with the username nagiosadmin \u0026amp; the password given at the beginning of the installation.\nCan check the connectivity to the agent on the windows host using the check_ncpa add-on command.\n/usr/local/nagios/libexec/check_ncpa.py -H 192.168.122.53 -t \u0026#39;windows-host\u0026#39; -P 5693 -M system/agent_version OK: Agent_version was [\u0026lsquo;2.4.1\u0026rsquo;]\nFor the debian one (changing values).\n/usr/local/nagios/libexec/check_ncpa.py -H 192.168.122.165 -t \u0026#39;debian-host\u0026#39; -P 5693 -M system/agent_version OK: Agent_version was [\u0026lsquo;2.4.1\u0026rsquo;]\n(note: the -H parameter is the host\u0026rsquo;s hostname or its ip address, -t is for the token created by the host during the agent installation process, -P the used port \u0026amp; -M the called value)\nExample of active monitoring of the cpu load for both - same syntax. Refer to the ncpa documentation to gather other metrics.\n/usr/local/nagios/libexec/check_ncpa.py -H 192.168.122.53 -t \u0026#39;windows-host\u0026#39; -P 5693 -M cpu/percent -w 20 -c 40 -q \u0026#39;aggregate=avg\u0026#39; OK: Percent was 4.70 % | \u0026lsquo;percent\u0026rsquo;=4.70%;20;40;\nHere on the debian host.\n/usr/local/nagios/libexec/check_ncpa.py -H 192.168.122.165 -t \u0026#39;debian-host\u0026#39; -P 5693 -M cpu/percent -w 20 -c 40 -q \u0026#39;aggregate=avg\u0026#39; OK: Percent was 0.00 % | \u0026lsquo;percent\u0026rsquo;=0.00%;20;40;\nTo add the hosts to the nagios web interface for passive monitoring: the Nagios Server requires their hosts .cfg configuration files.\nStarting by creating two directories to organise them: windows-hosts \u0026amp; debian-hosts (see hosts configuration files recommendation).\nmkdir /usr/local/nagios/etc/windows-hosts mkdir /usr/local/nagios/etc/debian-hosts Added them to the /usr/local/nagios/etc/nagios.cfg nagios configuration file.\n47 48 49 50 51 52 53 54 55 56 # You can also tell Nagios to process all config files (with a .cfg # extension) in a particular directory by using the cfg_dir # directive as shown below: cfg_dir=/usr/local/nagios/etc/windows-hosts cfg_dir=/usr/local/nagios/etc/debian-hosts #cfg_dir=/usr/local/nagios/etc/servers #cfg_dir=/usr/local/nagios/etc/printers #cfg_dir=/usr/local/nagios/etc/switches #cfg_dir=/usr/local/nagios/etc/routers These files should define the host using define host and the services to monitor by giving the check_* commands.\nHere is an example of the define host used for monitoring the debian host in /usr/local/nagios/debian-hosts/debian-host.cfg.\n1define host { 2 host_name debian-host 3 address 192.168.122.165 4 check_command check_ncpa!-t \u0026#39;debian-host\u0026#39; -P 5693 -M system/agent_version 5 max_check_attempts 5 6 check_interval 5 7 retry_interval 1 8 check_period 24x7 9 contacts nagiosadmin 10 notification_interval 60 11 notification_period 24x7 12 notifications_enabled 1 13 register 1 14} host_name is used for nagios to identify the host on its interface. The check_command defines the checked parameter for the HOST STATUS.\nHere is an example to implement the cpu load check to the configuration file by defining a service to monitor.\n16define service { 17 host_name debian-host 18 service_description CPU Load 19 check_command check_ncpa!-t \u0026#39;debian-host\u0026#39; -P 5693 -M cpu/percent -w 20 -c 40 -q \u0026#39;aggregate=avg\u0026#39; 20 max_check_attempts 5 21 check_interval 5 22 retry_interval 1 23 check_period 24x7 24 notification_interval 60 25 notification_period 24x7 26 contacts nagiosadmin 27 register 1 28} A command can be used to check errors in your *.cfg configuration files before restarting nagios service. Here an example with the debian host created.\n/usr/local/nagios/bin/nagios -v /usr/local/nagios/etc/debian-hosts/debian-host.cfg Finishing by restarting Nagios system service to make changes take effect.\nsystemctl restart nagios overview # Once logged into the nagios web interface, the hosts status can be see in the Hosts section of the Current Status.\nThe services status are available in the Services one.\nclose # I found the nagios documentation quite well explained (using \u0026amp; compiling nagios from source) although sometimes obsolete - relating to discontinued stuff or frustrating - some requirements missing from current repos.\nNagios Core is very very old, when doing my searching i was often finding myself reading forums posts from 2007-2009.\nAnother thought on Nagios Core is that its \u0026ldquo;unalive\u0026rdquo; today. Near nothing need to be changed in the code, because it does what it said on the tin.\nThe only things its team wants to work on now might be their cost solutions. However it\u0026rsquo;s for mission criticial tasks or companies wanted stuff that people charge off.\nThe real power is in the nagiosXI from a reddit user, and i found it sad from.\nOtherwise, i like nagios core flexibility by its check commands \u0026amp; its community that is still alive \u0026amp; contribute to plugins \u0026amp; add-ons.\n","date":"2023-07-25","permalink":"/posts/nagios-introduction/","section":"Posts","summary":"understanding Nagios principles \u0026amp; deploying","title":"nagios introduction"},{"content":" Note i try to keep this page as up to date as possible\nyou can always contact me if the last update is too old Work # i am a second-grade Network \u0026amp; Telecommunication bachelor student at University of Pau and the Adour Region\ni do a work-study as an Network \u0026amp; System Administrator for a french IT service delivery company\nFreetime # exploring \u0026amp; creating Github repos about IT related stuff\n","date":"2023-07-19","permalink":"/now/","section":"","summary":"Note i try to keep this page as up to date as possible","title":"Now"},{"content":" Skills # my interests are oriented in networks \u0026amp; telecommunications, enjoying learning new technos on bare metal, using embedded or virtualization (gns3, packet tracer)\ni\u0026rsquo;ve been a linux enthusiast for years, having over 3 years of layer 2-7 administration of gnu/linux distributions for daily use (rhel, debian, alpine, arch, nixos)\ni have a strong background in virtualization \u0026amp; containerization using qemu/kvm, proxmox, gns3, cisco pt, docker + compose \u0026amp; k8s\ni also love programming using java, python \u0026amp; bash\nStudy # i have a French high-school bachelor general degree in mathematics \u0026amp; computer science\ni am a second-year student at University of Pau and the Adour Region\nHobbies # i like learning as much as i can about everything\ni am an IT privacy \u0026amp; security enthusiast\n","date":"2023-07-18","permalink":"/about/","section":"","summary":"Skills # my interests are oriented in networks \u0026amp; telecommunications, enjoying learning new technos on bare metal, using embedded or virtualization (gns3, packet tracer)","title":"About"},{"content":"","date":"0001-01-01","permalink":"/authors/","section":"Authors","summary":"","title":"Authors"},{"content":"","date":"0001-01-01","permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":"0001-01-01","permalink":"/tags/gnu/linux/","section":"Tags","summary":"","title":"gnu/linux"}]