[{"content":"you have found my website somehow\nyou can find out more about me in the about section\nthere is the now section for my current life in progress\n","date":"2023-08-21","permalink":"/","section":"","summary":"you have found my website somehow","title":""},{"content":"","date":"2023-08-21","permalink":"/posts/","section":"Posts","summary":"","title":"Posts"},{"content":" software management differences\n\u0026amp; package managers for windows software management # Highlighting gaps \u0026amp; problems from the non software management in windows.\ninstallation # To install a software in windows, an installer needs to be searched in a browser, downloaded (.exe, .msi\u0026hellip;) \u0026amp; executed to download the wanted software.\nBy downloading an installer externally, the chances to install the wrong software, install additional ones or a malware is increased.\nupdates # Software updates are individuals, each software must search for its update - background apps, when the computer starts etc.\nNor the Windows Update or the Microsoft Store will check for the external installed software updates.\nuninstallation # Most of the time, software can be found in the control panel or the apps section of the windows settings.\nHowever, software installed in non common path are not listed alongside those.\nDependencies installed to use them usually remain after uninstalling the software - how many programs in the control panel are wanted or used\u0026hellip;\nsome improving # The Microsoft Store improves the software management in windows.\nThe software are trusted because approved \u0026amp; listed by Microsoft.\nSoftware are searched \u0026amp; directly downloaded, no risks to download \u0026amp; execute a malicious program found online.\nThe software installed from the Microsoft Store can be all updated at once, no background apps etc.\nHowever, the ms store apps list doesn\u0026rsquo;t cover all the wanted users apps.\nreal improvement # Windows, maybe knowning how software are handled on linux, created their package manager.\nPackage managers are tools used to install \u0026amp; manage software \u0026amp; their packages.\nLinux users use them to quickly install software, update their system, their software \u0026amp; packages whenever they want, and also uninstall software including unused dependencies.\nA package manager is a simpler \u0026amp; cleaner way to manage your system software \u0026amp; updates.\npackages managers can also be used in companies to avoid installing software one by one on hundred PCs, run grouped updates, install specific ver. of a software \u0026amp; more\nwindows package managers # Package managers can be found for different purposes.\nHere are some of them, how to install \u0026amp; use them.\nsmooth transition # To switch into a package manager easily, all installed apps can be found in the Control Pannel, under Programs, Uninstall Programs.\nCertain other apps can be found in the Settings -\u0026gt; Applications.\nEither, this command can be launched in an admin Terminal to list your installed apps - games not include, just the launchers\nGet-ItemProperty HKLM:\\Software\\Wow6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\* | Select-Object DisplayName, DisplayVersion, Publisher, InstallDate | Format-Table –AutoSiz Export the list to a file\nGet-ItemProperty HKLM:\\Software\\Wow6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\* | Select-Object DisplayName, DisplayVersion, Publisher, InstallDate | Format-Table –AutoSize \u0026gt; C:\\programs.txt winget # Winget is the windows package manager shipped with windows 11 - can be installed in windows 10 using a command.\nAdobe products \u0026amp; other microsoft trusted software can be installed quickly \u0026amp; securely through it.\nWith vlc for example, instead of opening a web browser, searching vlc, downloading the installer, executing it, clicking next\u0026hellip;\nOpen a Terminal or a Powershell \u0026amp; run.\nwinget install vlc multiple software can be installed at once, to install gimp \u0026amp; vlc for example winget install gimp vlc\nWinget can search wanted packages, example with gimp.\nwinget search gimp List installed packages.\nwinget list Uninstall one or more packages.\nwinget uninstall vlc gimp Upgrade one or all packages at once.\nwinget upgrade --id Adobe.Acrobat.Reader.64-bit winget upgrade --all Configuration can be exported if moving from a pc to an other.\nwinget export packages.json winget import packages.json ninite # Leaving the command line, ninite aims to install \u0026amp; update your software all at once using a .exe.\nVery usefull after a windows installation to download all your software at once if you didn\u0026rsquo;t have winget at first.\nRunning it more than once will update the selected software.\nOn their website, software to download can be choose, from that it will generate a .exe to install them.\nSelect software \u0026 \"Get Your Ninite\" chocolatey # Most used package manager in windows, appeared before winget in 2011: chocolatey is a more open package manager.\nMore packages are in chocolatey, they are moderated \u0026amp; doesn\u0026rsquo;t contain malware or bloatware.\nChocolatey is more open, more widely used software are present, those who are not verified yet by windows.\nA single powershell command can install chocolatey, runned as admin.\nSet-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString(\u0026#39;https://community.chocolatey.org/install.ps1\u0026#39;)) Chocolatey has a strong \u0026amp; native gui called chocolateygui to avoid using commandline.\nchoco install chocolateygui The commands are similar to winget with the choco command.\ni personally use chocolatey when i got to be on windows \u0026amp; find it more convenient to use, also for new users because of its native gui\nTo list local installed software\nchoco list --local To upgrade all packages\nchoco upgrade all And the ultimate command to remove a software with its dependencies if not use by other ones (those commands are the same).\nchoco uninstall package --removedependencies choco uninstall package -x if an other software uses the removed one dependencies, chocolatey doesn\u0026rsquo;t uninstall them \u0026amp; tells you it didn\u0026rsquo;t.\nbonus macos # The macos software management is different from the windows one.\nAlthough, homebrew has the same role as chocolatey does for macos.\n","date":"2023-08-21","permalink":"/posts/win-pkgs-mngers/","section":"Posts","summary":"software management differences","title":"software in windows"},{"content":"","date":"2023-08-21","permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"","date":"2023-08-21","permalink":"/tags/windows/","section":"Tags","summary":"","title":"windows"},{"content":"","date":"2023-08-19","permalink":"/tags/cheat-sheet/","section":"Tags","summary":"","title":"cheat-sheet"},{"content":" introduction # here i expose my usages of ssh \u0026amp; some advanced notions about it\ni\u0026rsquo;ll speak about the ssh protocol as the openssh implementation\ni\u0026rsquo;m tempted to write my articles in lower case only as i usually write so outside\nread this article like a cheat sheet\nfundamentals # secure shell - ssh, is a very versatile protocol but generally used to access a remote server command line securely\nencapsulate in tcp/ip use port tcp/22 by default use asymetric cryptography the first time connecting to a remote ssh server, w/ or w/out a private key, you have the server public key fingerprint prompted asking you if you trust it or not\nif yes, it is paste in ~/.ssh/known_hosts w/ the associate ip address \u0026amp; encryption protocol; its trusted by the local machine\nmodifications # on the ssh server side, connexions behaviour can be modified in /etc/ssh/sshd_config\nsshd stands for ssh daemon\nbasic ssh setup let you connect to an ssh host entering an username \u0026amp; a password beside root\nfor the changes to take effect, restart the sshd service\nsystemctl restart sshd good practices # change the ssh access port from the port 22\ncheck if the root login is disabled (yes by default)\nusing ssh keys (authentication) + username \u0026amp; password (authorisation) or certificates\nuse differents keys to access different servers\nuse ~/.ssh/config to manage easily keys \u0026amp; remote servers\nuse a passphrase for your private keys\nkeys # the server has a public key that everyone can see, only you have the private key to connect to the server; public key -\u0026gt; the lock, private key -\u0026gt; the key\u0026hellip;\nprivate \u0026amp; ssh keys are generated simultaneously, various algorithms could be choosen\nkeys default location is ~/.ssh - perfectly fine with it\nssh-keygen # to generate your keys -C can be used to add a comment to a key, -t choose the algorithm\nadd a public key to a remote host, after running the ssh-keygen command\nssh-copy-id -i path/to/key.pub username@remotehost or\ncat path/to/key.pub | ssh username@remotehost \u0026#34;mkdir -p ~/.ssh \u0026amp;\u0026amp; cat \u0026gt;\u0026gt; ~/.ssh/authorized_keys\u0026#34; passphrases # passphrases can be added to private ssh keys, preventing the usage of the key if stolen\nconfig file # ~/.ssh/config serve the ssh client to manage its remote hosts\nor /etc/ssh/sshd_config\nhost remotename Hostname remotehost User username Port sshport IdentityKey /path/to/privatekey after that config, no need to restart a service\nssh remotename certificates # works the same way tls/ssl does for https\nuse to scale ssh access because having data like an expiration date and permissions\nA CONTINUER\nfile transfering # ways to transfer ressources to \u0026amp; from a remote host\nfrom remote host # gather a file from a remote host\nscp username@remotehost:/remote/path/to/file . gather a folder from a remote host\nscp -r username@remotehost:/remote/path . synchronising files from a remote host using rsync\nrsync username@remotehost:/remote/path/to/file . rsync -r username@remotehost:/remote/path . to remote host # send a file to a remote host\nscp filename username@remotehost:/remote/path send a folder to a remote host\nscp -r directoryname username@remotehost:/remote/path rsyncing\nrsync filename username@remote-host:/remote/path rsync -r directoryname username@remote-host:/remote/path mount remote folder # mount a remote directory on local system w/ sshfs (ssh file system)\napt install -y sshfs # depends on your package manager mkdir mount-dir mount the remote directory in the created folder\nsshfs username@remote-host:/remote/path mount-dir changes in the folder will also be made in remote-host:/remote/path\nto unmount it\numount mount-dir sftp # ssh file transfer protocol, or secure file transfer protocol\ncan be used with the sftp command to open a remote shell\nsftp username@remotehost can navigate with pwd, ls, cd \u0026amp; use get or put to gather or send ressources\nget filename put filename or\nget /path/to/remote/file /path/to/local/directory put /path/to/local/file /path/to/remote/directory a gui like filezilla for easier transfer applications can be done\nx11 forwarding # use remote app gui on local host\nconfig remote server # run with root or sudoer\napt install -y xauth # to forward x11 packets, depends pkgs manager allowing x11 fowarding in /etc/ssh/sshd_config by removing #\n87#AllowAgentForwarding yes 88#AllowTcpForwarding yes 89#GatewayPorts no 90X11Forwarding yes 91#X11DisplayOffset 10 92#X11UseLocalhost yes 93#PermitTTY yes systemctl restart sshd ssh into it \u0026amp; try launching xapplications\ndepending on the remote server configuration, some extra work could be intended\nssh tunneling # to access specific ressources, vpns expose an entire network which cannot be relevant for security reasons\nssh tunneling encapsulate a layer 3-7 traffic between 2 hosts over ssh\nssh encryption is added to the communication - so that if an unsecured communication is used by the application, it is encrypted\nit can also be use to bypass firewall restrictions by fowarding ports\nuncontrolled or unmonitored tunnels can be used as backdoors, for data exfiltration, bouncing attacks \u0026amp; more\nlocal fowarding # forward a port from a ssh client to a ssh server (launched from the ssh client)\nextremely usefull to access a remote service denyied by a firewall, it needs the remote host to be accessible with ssh\n%%{init: {'theme':'dark'}}%% graph LR a(local machine) b(firewall) c(remote server) a---b b--\u003ec let\u0026rsquo;s say you have a raspberry pi at 192.168.1.12 w/ ssh access via pi user hosting a web server locally on its 5000 port \u0026amp; you want to access locally through your machine\nssh -N -L 127.0.0.1:8080:127.0.0.1:5000 pi@192.168.1.12 ssh -N -L 8080:127.0.0.1:5000 pi@192.168.1.12 -N prevents from running an active ssh session\nall traffic (http requests) sent to localhost:8080 on local machine will be forwarded to raspberry pi\u0026rsquo;s 5000 port - responses sended back to you\nLocalForward variable can be edited in the config file to avoid putting it every connexion\nreverse ssh tunnels # also called remote ssh tunnels or ssh remote forwarding\nforward a port on a remote host (ssh server) to a port on a local machine (ssh client)\ninitialised by the remote server\nused to access a service, hosted on a local network, from another network (or internet)\n%%{init: {'theme':'dark'}}%% graph LR a(remote sever) b(firewall) c(local machine) a---b b--\u003ec widely use to exploit systems on private networks\nlet\u0026rsquo;s say: the remote server is locally running a web server on its port 80, its local network address is 192.168.1.23\nthe local machine public ip address is 8.8.8.8 - google one \u0026amp; accessible w/ ssh\nssh -N -R localhost:8080:192.168.1.23:80 root@8.8.8.8 ssh -N -R 8080:192.168.1.23:80 root@8.8.8.8 the service running the remote server port 80 will be accessible by the local machine loopback address on port 8080\nprevent tunnels # PermitTunnel no can be changed in /etc/ssh/sshd_config to prevent tunnels creation\nssh bastions # can be called ssh jump servers, ssh proxies or ssh agent forwarding\na single server accessible via ssh from the internet to redirect ssh sessions to others hosts\nusefull to centralise \u0026amp; secure ssh connexions in a corporate network to reduce the \u0026ldquo;attack surface\u0026rdquo; to just one machine\nteleport is an opensource solution if not using openssh\nadvices # only the ssh port is accessible for incomming connexions the ssh port is changed from 22 root user disabled be very aware of the security implementations prevent users to ssh into the bastion itself other purposes # can be used to encapsulate data, doing other services than transporting ssh packets\ncan be used as a \u0026ldquo;vpn\u0026rdquo;, doing dynamic ssh port forwarding \u0026amp; encapsulate your data w/out exposing an entire network (ssh + socks5 proxy)\ncommand # ssh -J bastionaddress username@remotehost -J parameter can be avoided by configuring the ProxyJump permanently in config file\nparameters saw in config file can be added too\nHost remotehost ProxyJump bastionaddress creation of an ssh user that cannot connect into ssh to the ssh bastion itself called bastionuser\ngive this user to anyone using the bastion\nMatch User bastionuser PermitTTY no X11Forwarding no PermitTunnel no GatewayPorts no ForceCommand /usr/sbin/nologin then modify the parameters\nssh -J bastionuser@bastionaddress username@remotehost for the ~/.ssh/config\nHost remotehost ProxyJump bastionuser@bastionaddress chrooting # change root (chroot) changes appareant root directory for the running user to a root directory called a chrooting jail\nssh support chrooting: restricting an ssh session to a directory\nyou can create a fancy one manually but it is very long, for each user\nrssh is a simpler way to do so\ncreate a new user with /usr/bin/rssh shell\nuseradd -m -d /home/chrooteduser -s /usr/bin/rssh chrooteduser passwd chrooteduser or change existing user shell to /usr/bin/rssh\nusermod -s /usr/bin/rssh chrooteruser works for sftp \u0026amp; scp\ndnssec # ssh use tofu trust on first use, it trusts the ssh server the first time connecting to it\nif targetted by a man-in-the-middle attack, you could be at risk using ssh connexion\ndnssec has many features to improve the standard \u0026amp; old dns protocol, one of which is: dns answers are not tampered\nit is possible that an attacker can hijack ssh connexions \u0026amp; create valid dnssec responses, but less likely\nuse ssh-keygen as usual w/ an url using dnssec \u0026amp; a . at its end to stop the domain for beeing repeated twice\nssh-keygen subdomain.domainwithdnssec.tld. then\nssh -o VerifyHostKeyDNS=yes subdomain.domainwithdnssec.tld. ","date":"2023-08-19","permalink":"/posts/ssh/","section":"Posts","summary":"introduction # here i expose my usages of ssh \u0026amp; some advanced notions about it","title":"ssh explored"},{"content":" overviewing centreon it \u0026amp; getting fully hands-on introduction # The last article in this series will be devoted to discover \u0026amp; use Centreon IT.\nFeel free to correct me by email if i\u0026rsquo;ve said something wrong.\npresentation # Centreon IT is a french open-source based monitoring solution.\nIt is highly inspired by Nagios, since it was a Nagios frontend at its beginning.\nCentreon\u0026rsquo;s solutions has the same Nagios\u0026rsquo; plugins \u0026amp; hosts systems but can keep their hands on the plugins with their repository - where the community can freely publish them for Nagios.\nCentreon is a profit-oriented company who has a business model based on licensing the number of hosts monitored.\nThe free solution called Centreon IT-100 is licensed for 100 monitored hosts only - their Free Trial. Other differences with the commercial editions are listed in their comparison table.\nnamely # Informations on how Centreon IT works \u0026amp; its specific features.\norganisation # Centreon claims their solutions can be hosted on site, called OnPrem, or cloud-based, called Cloud.\nCentreon instances always works with a Central Server, called centreon-central used to configure monitoring, display \u0026amp; operate the collected data.\nTo monitor multiple sites, instances can be deployed \u0026amp; attached to the Central Server, the Remote Servers.\nMonitored data is gathered using Pollers, attached to the Central or a Remote Server.\nHere is what a Centreon OnPrem distributed architecture should looks like according to Centreon.\n%%{init: {'theme':'dark'}}%% graph TD central[Central Server] remote0[Remote Server] remote1[Remote Server] remote2[Remote Server] poller0((Poller)) poller1((Poller)) poller2((Poller)) poller3((Poller)) poller4((Poller)) poller5((Poller)) central---remote0 \u0026 remote1 \u0026 remote2 remote0---poller0 \u0026 poller1 remote1---poller2 \u0026 poller3 remote2---poller4 \u0026 poller5 The Centreon Cloud architecture does away with Remote Servers, as Pollers are connected to the Central Server via the cloud - using a vpn.\n%%{init: {'theme':'dark'}}%% graph TD central[Central Server] poller0((Poller)) poller1((Poller)) poller2((Poller)) central --- poller0 \u0026 poller1 \u0026 poller2 hosting # Centreon documentation guides to host onprem \u0026amp; cloud solutions on different supports.\nFor an overview, they give *.ovf \u0026amp; *.ova images for virtual box \u0026amp; vmware respectively.\nInstallations alongside gnu/linux distros is preferable for production use.\nThe documentation guides it for RHEL, Alma/Oracle/Rocky Linux since they are rhel based distros - (or \u0026ldquo;were\u0026rdquo; since rhel closed their source).\nLess attention is putted on Debian, the documentation is deprecated for it.\nIn the past - until ver. 21.10, they used to create *.iso images to install their solutions alongside centos.\nconnectors \u0026amp; plugins # Data collection performed by Centreon models called Monitoring Connectors which have Plugins assets.\nPlugins have the same function as Nagios ones.\nInstalled \u0026amp; used by pollers, they are sets of commands to monitor various kinds of metrics, on differents type of hosts regarding many protocols.\nPlugins \u0026amp; connectors are maintained in their centreon-plugins \u0026amp; centreon-connectors repositories, where it seems community can contribute.\nAlthough it\u0026rsquo;s opensource, a license is required to access the full Plugin Pack on their solutions.\ndeploying # Installing Centreon IT-100, doing a simple windows \u0026amp; linux hosts monitoring.\nrequirements # The infrastructure size depends on the number of hosts to monitor.\nCentreon recommends using lvm to manage their file systems - working fine without, but should be planned for production use.\nA stand-alone central server is used under 500 hosts. Pollers every 500 hosts are expected with a database server if more than 2'500 hosts.\nFor production use, it would be a good idea to think about scalability.\nSince there would be too much information to display (partitionning, specs, infrastructure), i let you refer to their infrastructure sizes charts.\ninfrastructure # An infrastructure similar to that used in the nagios article will be deployed.\nFollowing the requirements - partially since it is not for production use, a stand-alone Central server will be deployed with its poller.\nHere is what the used infrastructure looks like.\n%%{init: {'theme':'dark'}}%% graph TD subgraph lan[LAN] router{Router} switch[Switch] centreon(Centreon Central Server\n192.168.122.166) linux(Debian Host\n192.168.122.164) win(Windows Host\n192.168.122.251) mariadb[(MariaDB server)] poller((Poller)) end wan{WAN}---router router---switch switch---centreon switch---linux switch---win centreon-.-mariadb \u0026 poller installation # Centreon IT will be installed without license on Debian 11.\nI made an installation script available on Github.\nThis script installs Centreon IT from added Centreon\u0026rsquo;s apt repositories \u0026amp; install a secured mysql server through mariadb.\nTo execute it, run the following commands.\nmkdir testing \u0026amp;\u0026amp; cd testing wget https://github.com/xeylou/centreon-overview/deb11-centreon-install.sh chmod +x debian-centreon-install.sh ./debian-centreon-install.sh Installation can be resumed going on the Centreon web interface http://192.168.122.166.\n(cannot highlight forms natively, so i specify the changes, otherwise i just do next, install or finish)\nMore dependencies than the ones loaded could be presented as Not loaded for debugging (if not using the script).\nCreation of an admin account for the Centreon interface.\nConnexion to the db server. The root password was asked \u0026amp; created by the script at the end.\nUsed localhost (so 127.0.0.1 or ::1) for the db server ip address, since its hosted on the same host as the future centreon central server.\nCreation of a db user to perform data querries - for security purposes, not doign them with an admin one.\nLogin created step 5 Admin information.\nThis is the after-loggin page.\nAfter the installation, the Central server poller is not working.\nAdditionnal steps are required to start monitoring.\nGo to the poller section to see it.\nNeed to click on Export configuration.\nSelect the Central poller.\nCheck Move Export File.\nThen Export.\nAfter that, run the following commands, keep their order without modifying them.\nsystemctl restart cbd centengine systemctl restart gorgoned systemctl start snmptrapd centreontrapd systemctl start snmpd Then the poller starts working.\n(the red circle at top left, to the right of Pollers logo disappears later, see screenshots below)\nsnmp plugins # Centreon recommends using their snmp implementation plugins to gather metrics - cpu load, memory usage etc.\nUsage of the snmp protocol garantees the monitoring to work as intended since the protocol is universal - rather than installing an agent.\nPlugins can be added using the web interface or by using the system package manager (dnf for rhel based distros \u0026amp; apt for the debian family).\nHere is the installation of the needed snmp plugins using the web interface.\nAdding the linux snmp plugin clicking +.\nBase Pack is an expected dependency that will be installed choosing Apply.\nDoing the same for windows snmp plugin, no more dependency needed.\nResult.\nOn wanted monitored hosts, snmp must be configured and working.\nlinux host # Note I\u0026rsquo;ve explained what were done with snmp rather than just throwing you my script as you may need this explainations to monitor other devices like switches or routers. (which doesn\u0026rsquo;t mean i haven\u0026rsquo;t made one) For our needs, according to the debian snmp page, a repo needs to be added to /etc/apt/source.list.\n1# deb cdrom:[Debian GNU/Linux 11.7.0 _Bullseye_ - Official amd64 NETINST 20230429-11:49]/ bullseye main 2 3#deb cdrom:[Debian GNU/Linux 11.7.0 _Bullseye_ - Official amd64 NETINST 20230429-11:49]/ bullseye main 4 5deb http://deb.debian.org/debian/ bullseye main 6deb-src http://deb.debian.org/debian/ bullseye main 7 8deb http://security.debian.org/debian-security bullseye-security main 9deb-src http://security.debian.org/debian-security bullseye-security main 10 11# bullseye-updates, to get updates before a point release is made; 12# see https://www.debian.org/doc/manuals/debian-reference/ch02.en.html#_updates_and_backports 13deb http://deb.debian.org/debian/ bullseye-updates main 14deb-src http://deb.debian.org/debian/ bullseye-updates main 15 16# This system was installed using small removable media 17# (e.g. netinst, live or single CD). The matching \u0026#34;deb cdrom\u0026#34; 18# entries were disabled at the end of the installation process. 19# For information about how to configure apt package sources, 20# see the sources.list(5) manual. 21 22# snmp needs 23deb http://httpredir.debian.org/debian bullseye contrib non-free After that, the needed packages can be installed.\napt update apt install -y snmp snmptrapd snmp-mibs-downloader Checking if the snmp service is running properly.\nsystemctl status snmpd If not, it needs to be started.\nsystemctl start snmpd Before making changes to the snmp daemon configuration file /etc/snmp/snmpd.conf, a backup is always welcome.\ncp /etc/snmp/snmpd.conf{,.old} The snmp protocol will listen for connections on all interfaces on port 161 udp for ipv4 \u0026amp; ipv6.\nSNMP will wait for a specific ip address under a certain community called public here.\nModifications are done in /etc/snmp/snmpd.conf.\n41# agentaddress: The IP address and port number that the agent will listen on. 42# By default the agent listens to any and all traffic from any 43# interface on the default SNMP port (161). This allows you to 44# specify which address, interface, transport type and port(s) that you 45# want the agent to listen on. Multiple definitions of this token 46# are concatenated together (using \u0026#39;:\u0026#39;s). 47# arguments: [transport:]port[@interface/address],... 48 49agentaddress udp:0.0.0.0:161,udp6:[::]:161 67# rocommunity: a SNMPv1/SNMPv2c read-only access community name 68# arguments: community [default|hostname|network/bits] [oid | -V view] 69 70# Read-only access to everyone to the systemonly view 71# rocommunity public default -V systemonly 72# rocommunity6 public default -V systemonly 73rocommunity public 192.168.122.166 After that, the snmp service needs to be restarted.\nsystemctl restart snmpd This command can be run from the Centreon Central Server to check if the configuration is working.\nsnmpwalk -v2c 192.168.122.164 -c public If it does, a lot of text will be displayed rather than this output: Timeout: No Response from 192.168.122.164.\n(if you are working with snmp layer: this command retrieves records from mib by going through each oid running automatic getnext requests, so you don\u0026rsquo;t need a command for each oid or node, on snmp ver. 2c asked with \u0026ldquo;public\u0026rdquo; community)\nwindows host # The windows host is a windows server.\nThe snmp protocol will be enabled on it, authorizing only the centron-central to communicate via a community named public.\nOn the Server Manager window.\n(here i can nicely highlight the forms)\nSelect the hostname of the windows server.\nNo need to add anything, just go Next.\nSearch for the SNMP Service \u0026amp; enable SNMP WMI Provider.\nRight after that go Next.\nThe snmp service needs to be configured in the Server Manager window.\nFind the SNMP Service among the services.\nAdd a community, here public, the same as the one configured on the debian host.\nRead Only is preferable because nothing has to be changed, just the metrics to be gathered.\nThe Centreon server needs to be trusted by entering its ip address.\nLet\u0026rsquo;s click Ok (does Apply \u0026amp; quit).\nThen Restart the service to make the changes take effect.\nThe same command used to check the connectivity of the debian host can be used for the windows one, changing the ip address.\nsnmpwalk -v2c 192.168.122.251 -c public adding hosts # Before adding the hosts to Centreon, it would be pleasant to check their snmp connectivity.\nsnmpwalk -v2c 192.168.122.251 -c public snmpwalk -v2c 192.168.122.164 -c public If the Centreon server can reach them, they can be added to its interface.\nGo to the Hosts configuration.\nClick on Add.\nFilling with the informations for debian host \u0026amp; some arbitraty ones.\nSave.\n(the Default equals Yes for the two cases)\nDoing the same for the windows host informations.\nThe host are added, should looks like so.\nThe pollers need to actualize their configuration files to starts monitoring the hosts.\n(note the red Yes on Conf Changed) Export the configuration in a file for pollers but this time also restart them.\nTo see the hosts \u0026amp; their services status.\nAfter 5 minutes or a Force check.\nIncomming ping (echo requests) are blocked by the windows firewall by default in windows client \u0026amp; server.\nAlthough it is marked as critical, it doesn\u0026rsquo;t shows up like so in the services section at the top left\u0026hellip;\nadding services # More services can be monitored by adding them into the centreon interface.\nClick on Add. Services to monitor can be added according to what plugins are installed in the Centreon server.\nThe sheet with an eye is a small documentation on the command arguments, parameters, etc.\nThe Default options are Yes in the three cases.\nAn then export the configuration \u0026amp; restart the pollers to make changes take effect, like did at the end of adding hosts.\n(to avoid putting a third time the captures how to do it)\ndebugging # Passives checks commands can be seen, helping a lot for debugging.\nIt can also helps for active monitoring without dealing with the Centreon interface.\nHere is how to do so with the swap services.\nThe syntax is the same for the windows \u0026amp; the linux smp plugins except the --plugin option.\nThe services commands syntax are the same, the --mode option change for cpu, load, memory, uptime, etc.\nclose # Here are some commands that helped me (hope can help you) for debugging - apart from connectivity debugging, because i had to debug a lot compared to itop or nagios\nsystemctl status cbd systemctl status gorgoned systemctl status centreon systemctl status centengine systemctl status snmptrapd (btw the centreon service has never been active\u0026hellip;)\nThere are many more services to know \u0026amp; check to understand a problem at the beginning.\nIn Nagios, for the same kind of interface (checking hosts services) you just have the nagios service to check for errors.\nFor centreon, the gathering, the processing, the display parts \u0026amp; more are seperate ones.\nIt\u0026rsquo;s better seperating parts of codes for debugging or reliability, but having a single service that reports all problems can be pleasant (or just not so many services).\nI got hard times to find were a problem could come from sometimes, since the numbers of potential services problem was huge.\nI also understand that centreon as more features (graphs etc.) than nagios base, not xi.\nCentreon uses nagios plugins, in the same directory as nagios does by default\u0026hellip;\nNagios has a page dedicated to CVEs to prove their concern \u0026amp; patches. There may be one, but i haven\u0026rsquo;t found a \u0026ldquo;security concern\u0026rdquo; or issues page\u0026quot; for Centreon.\nThat\u0026rsquo;s disappointing since monitoring systems needs to be very aware of their security.\nCentreon systems were also targetted by russian attackers ( article 1, article 2).\nIt is a very good idea to display the command used to check a service, i think i hadn\u0026rsquo;t seen that in nagios.\n","date":"2023-08-12","permalink":"/posts/centreon-overview/","section":"Posts","summary":"overviewing centreon it \u0026amp; getting fully hands-on introduction # The last article in this series will be devoted to discover \u0026amp; use Centreon IT.","title":"centreon it overview"},{"content":"","date":"2023-08-12","permalink":"/series/exploring-monitoring-solutions/","section":"Series","summary":"","title":"Exploring Monitoring Solutions"},{"content":"","date":"2023-08-12","permalink":"/tags/monitoring/","section":"Tags","summary":"","title":"monitoring"},{"content":"","date":"2023-08-12","permalink":"/tags/open-source/","section":"Tags","summary":"","title":"open-source"},{"content":"","date":"2023-08-12","permalink":"/series/","section":"Series","summary":"","title":"Series"},{"content":" combodo itop tour \u0026amp; creating a living\nit service delivery infrastructure introduction # As with Nagios, i dived into Combodo iTop solution.\nEven though it is not a host monitoring solution, it can be a part of a monitoring infrastructure.\nI had harder time getting into it due to the notions to lean \u0026amp; to consider, inside \u0026amp; outside itop to use it properly.\nSo once again, i\u0026rsquo;d be very grateful if you\u0026rsquo;d consider correcting me if i said someting wrong.\nglossary # Defining mandatory acronyms for this post.\nITSM - IT Service Management\nType of tool usually used by companies to organise \u0026amp; deliver their IT services to their departments or to other companies. They can integrate monitoring tools or a help desk ticketing system for example.\nCMDB - Configuration Management Database\nTerm to define a database used to store \u0026amp; organise the hardware items \u0026amp; the software assets of a company or someone.\nITIL - Information Technology Infrastructure Library\nSet of relevant IT practices describing processes, procedures or actions for IT related operations like system administration or itsm management.\npresentation # Combodo is a 13-year-old french company who created itop, an open source, itil based, itsm \u0026amp; cmdb solution.\nThey are a profit based company, they created 2 non-free versions of itop for business purposes: essentials \u0026amp; professional/enterprise.\nThey also provide free \u0026amp; non-free external software to enhance itop utilisation like a front-end customiser or a network related manager; as weel as consultants.\nitop is typically used by the IT department of a company to organise services \u0026amp; implement a help desk ticketing system to the other departments.\nIt is also used by companies to deliver IT services to other companies as a service provider.\nunderstandings # Reviewing my understanding of itop\u0026rsquo;s main features.\nfundamentals # itop is based on apache, php, graphviz \u0026amp; mysql. However, it can run on nginx instead of apache with extra work.\nThe documentation is made for anyone who is susceptible to use itop.\ncmdb # The cmdb is the core of itop.\nThe cmd works with Objects, which are groups of Instances sharing the same patern.\n(considering the \u0026ldquo;Persons\u0026rdquo; object, each instance of this object would have the same patern: a name, a surname, an age etc.)\nThe cmdb can receive a populated *.csv file to create multiples instances of an object at once. (instead of entering one by one every member of a company for example)\nitop can receive custom objects but their implementation is not guided. The default ones are created without instances.\nObjects \u0026amp; instances are stored in the MySQL database.\nitsm # The itsm is integrated with the ticket management system \u0026amp; will be described using the itil way.\nWhen installing, itop proposes two ways to implement it: to deliver services to departments or to other companies; saw at the end of the presentation.\nThe itsm provides two types of tickets for end users: Users requests \u0026amp; Incidents.\nMandatory objects are needed to use them: Services, Contracts \u0026amp; SLAs.\nHere are their purposes \u0026amp; how they are related.\nServices\nAre defining what is provided by the service provider (IT department or company). Called to generate incidents or to supply users requests. Providers contracts are required.\nContracts\nSplited in Customer \u0026amp; Provider contracts. Customer one defines service(s) provided to/pucharsed by the customer + the SLAs. Provider one links internal ressources (CIs) used for the service(s) provided.\nSLTs - Service Level Target\nDefine metrics agreements between customers \u0026amp; providers. Two by default: TTO - Time To Own: time to take a ticket into account \u0026amp; TTR - Time To Resolve a ticket after creating.\nSLAs - Service Level Agreement\nGroup of SLTs defining the agreement between a provider \u0026amp; a customer for a given set of services.\nWhen a customer creates a ticket, it can select the service amongst the list of services defined for this customer.\nTickets deadlines are computed depending on the SLA signed with the customer.\ndefault objects # Native objects in itop are created during the installation process.\nThey should be used because related to itop principles.\nThe mandatory objects are covered here, many more can be used \u0026amp; discovered exploring itop.\nOrganizations\nCan be used for two purposes: name the different departments of a company when itop is used to deliver IT services within a company, or name the different companies a company is delivering IT services to.\nLocations\nAre used to group objects by geography - servers, organisations etc. A hierachy can be applied, locations can be linked to parents locations (example: inside the company A, there is room A \u0026amp; room B in which have differents servers in racks A \u0026amp; racks B)\nPersons\nDefine the persons contacts \u0026amp; responsabilities regarding the IT services delivered. Can be deployed using Profiles to quickly assign permissions (to the members of a department or a company).\nTeams\nUsefull to define permissions easier - all the HR \u0026amp; finance teams can access to\u0026hellip; -. Can also help the customer to communicate using the ticketing system.\nCIs - Configuration Items\nDescribe hardware devices: racks, pdus, network devices, servers, personal computers, hypervisors, vms etc. Templates are available for a large type of CIs.\nSoftware Installed\nPresent to easily index software installed on devices, licences \u0026amp; so on.\nServices\nObject used to define what actions or access is delivered as a service to a customer. Can be subcategorised - service A contains sub-service B \u0026amp; sub-service C.\nobjects agencement # Objects are related to each others by different means.\nI made graphs to show the links between them, or tried to.\nGraphs are generated using the following rules:\nRectangles are highest objects. Rounded objects are those receiving links. Text in lowercaps are instructions, uppercaps are objects name. Persons integrate Teams according to their Roles.\ngraph LR A[Persons] --\u003e|Roles| B(Teams) Teams belongs to Organizations.\ngraph LR A[Teams] --\u003e|belongs to| B(Organizations) Organizations are linked to Locations.\ngraph LR A[Organizations] --\u003e|are located| B(Locations) Regarding to only these objects, links can be created.\n(Persons -\u0026gt; Teams -\u0026gt; Organizations -\u0026gt; Locations)\nBefore doing that, there are links between objects covered in default objects.\nOrganizations are owning CIs. CIs are exposed to Services \u0026amp; are ruled by Provider Contracts. They can be related to Documents \u0026amp; appear in Tickets.\ngraph LR B[Organizations] --\u003e|owning| A(CIs) A --\u003e|exposed to| C(Services) D[Provider Contracts] --\u003e|rule| A A --\u003e|appear in| E(Tickets) A --\u003e|related to| F(Documents) Relations for Documents.\ngraph LR C[Organizations] --\u003e|owning| A(Documents) A --\u003e|used for| D(Contracts) D --\u003e|defining| A A --\u003e|give informations| F(CIs) A --\u003e|linked to| E(Services) All objects have relations to others at some point by different ways.\nIn addition to this, objects\u0026rsquo; instances have their own properties changing the relations between objects according to their needs.\nIt would be meaningless to create decent relations graphs for all objects, since their dependencies \u0026amp; relationships are to massive \u0026amp; could change each instance.\nDo not refer to this graph. Please read above. graph LR subgraph iTop Company View A[Persons] --\u003e|Roles| B(Teams) B --\u003e|parts of| C(Organizations) C --\u003e|are located| I(Locations) C --\u003e|owning| D(CIs) D --\u003e|related to| E D --\u003e|exposed to| G(Services) H(Provider Contracts) --\u003e|rule| D D --\u003e|appear in| F C --\u003e|owning| E(Documents) E --\u003e|used for| H H --\u003e|defining| E E --\u003e|linked to| G E --\u003e|give informations| D A --\u003e|see activity| D A --\u003e|attached to| F(Tickets) J[Other Objects] --\u003e|give properties| D J --\u003e|structure| E end Even though this graph seems valid for the most part, itop has many more objects than the ones covered. Links between them should be discovered \u0026amp; created using the frontend.\nimplementation # This sections will implement itop following a companies charts \u0026amp; an arbitrary infrastructure.\ncompanies charts # itop will be used by two companies: Company A which is the service provider \u0026amp; Company B who use their services.\nHere is the Company A agency graph.\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%% flowchart TD subgraph z[Company A Chart - Service Provider] subgraph m[CEO] a[Person A] end subgraph h[Executive Assistant] b[Person B] end subgraph i[Technical Manager] c[Person C] end subgraph j[Network \u0026 Sysadmins] d[Person D] e[Person E] end subgraph k[Work-Study Students] f[Person F] g[Person G] end end m---h m---i i---j i---k style z fill:#fff,stroke:#fff,stroke-width:4px Here is the Company B one.\n%%{init: {\"flowchart\": {\"htmlLabels\": false}} }%% flowchart TD subgraph z[Company B Chart - Consumer] subgraph a[CEO] b[Person H] end subgraph c[Technical Manager] d[Person I] end subgraph e[Sales Manager] f[Person J] end subgraph g[Head of Logistics] h[Person K] end subgraph i[\"Manufacturing Manager\"] j[Person M] end subgraph k[Assistant] m[Person N] end end a---c a---e c---g c---i e---k style z fill:#fff,stroke:#fff,stroke-width:4px All persons in the two companies will have access to an itop interface (in reality it is not necessary).\nrequirements # Here is the itop hardware recommendations from their documentation.\nActivity Recommendations Tickets/monthUsersCIs\u0026lt;200\u0026lt;20\u0026lt;50k\u0026lt;5k\u0026lt;50\u0026lt;200k\u0026gt;5k\u0026gt;50\u0026gt;200k ServersCPUMemoryMySQL DB sizeAll-in-one2vCPU4Gb10GbWeb+MySQL4vCPU8Gb20GbWeb+MySQL8vCPU16Gb50Gb infrastructure # There is 13 people who will potentially use itop in the two companies combined (\u0026lt; 50). The number of CIs will be under 50'000 \u0026amp; the tickets/month under 200.\nThe all-in-one server will be chose with itop \u0026amp; a MySQL server installed.\nNote For a production use, looking for expandability by choosing the seperate solutions would be a better choice. Here is the network infrastructure that will be used.\ngraph TD subgraph company-b[Company B Network] router-b{Router} switch-b[Network Switch] consumer-pc(Consumer Device) apache-b(Apache Server) end subgraph company-a[Company A Network] router-a{Router} switch-a[Network Switch] itop-server(Debian Machine\n2vCPU 4GB) db-server[(MySQL DB\n10GB)] itop(itop Community) apache-a(Apache Server) end wan{WAN} --- router-a \u0026 router-b router-a ---|192.168.122.0/24| switch-a switch-a ---|192.168.122.212| itop-server itop-server -.- db-server \u0026 itop switch-a ---|192.168.122.111| apache-a router-b ---|192.168.1.0/24| switch-b switch-b ---|192.168.1.1| consumer-pc switch-b ---|192.168.1.2| apache-b The Company A is providing an apache web server from their LAN as a service \u0026amp; monitor an other one from the Company B LAN.\ninstallations # I made an installation scripts for itop community \u0026amp; for a mysql server according to itop requirements.\n(yes, i could saved a lot of time not doing this, but foss)\nBoth scripts are interactive \u0026amp; made for debian - tested on debian 11 \u0026amp; 12, source code is on Github.\nThe itop server installation can be done running the following commands.\nmkdir itop_install \u0026amp;\u0026amp; cd itop_install wget https://github.com/xeylou/itop-tour/install-scripts/debian-itop-install.sh chmod +x debian-itop-install.sh ./debian-itop-install.sh Here to install the mysql server.\nmkdir mysql_install \u0026amp;\u0026amp; cd mysql_install wget https://github.com/xeylou/itop-tour/install-scripts/debian-mysql-install.sh chmod +x debian-mysql-install.sh ./debian-mysql-install.sh An external mysql database can be used without this installation script, an full privilieged user for this database is needed to use itop.\nThe installation can be resumed at http://192.168.122.212.\n(highlighted forms are clicked/changed values)\nThe warning says the used php version (latest) is not tested for this itop version by Combodo. (not appening with debian 11 because its repositories has an older php version) The Server Name is localhost because the itop instance \u0026amp; the mysql server are on the same host - can be replaced by the ip address of the external mysql server if using the seperate solution.\nThe Login \u0026amp; the Password was created during the debian-mysql-install.sh script process - asked at the beginning -. The database name found was also created during the installation process. Person C will have admin privilieges for this itop instance, since it is the Technical Manager. (can add more admins after)\nThe Language set is for this user only. Here the Default Language for all users can be changed. Can also be changed by individual users after deploying. Since the Company A acts as a service provider, the second option is chose. The first option should be kept if delivering IT services to company departements. Simple Ticket Management can be chose to get rid of SLTs \u0026amp; SLAs. The Customer Portal is the itop interface but reagenced for users tickets. If not chose, tickets should be created using command-lines method or the rest api. cmdb confirguration # The cmdb (organizations, persons, teams etc.) needs to be configured first.\nDepending on the company/ies \u0026amp; the infrastructure/s sizes, it could take some time to populate.\nExporting \u0026amp; importing csv files is a great option to configure it quickly. Here is a video from itop explaining how to do so (i still think putting mine will be worse).\nSynchronizing csv files (itop server \u0026amp; an editor side) can also be done to avoid entering each modification manually, scheduling this task to. ELDAP \u0026amp; AD services can also be used instead of this method.\nManual objects implementation \u0026amp; modification can also be done. A rest api is also present for external use cases.\nitsm overview # The itsm is following the cmdb configuration: users created, teams, organizations, services, contracts etc.\nExternal User profile for the iTop User object have a dashboard to create requests according to purchased services.\nThe user can change his Phone number, Location according to his company\u0026rsquo;s locations in the cmdb, the language to use or his profile picture.\nIt can also rename his function inside the company or change his password.\nWhen entering in New request, according to default objects, the services can be defined in sub-services to help the end user.\nThe provider has the itop dashboard (administrators like person c or other profiles) to interract with created tickets.\nTo avoid putting a gigantic amount of screenshots to show how the itsm works, here is itop video for that (better than the ones i made i think\u0026hellip;).\nA designer is available to custom the itsm interfaces.\nmonitoring # Once the cmdb is configured, links can be done between hardware \u0026amp; Application Services for the end users.\nThey are created using Contracts (Customer \u0026amp; Provider) with SLAs etc.\nSince itop is an itsm \u0026amp; cmdb solution, it doesn\u0026rsquo;t have a proper monitoring system.\nHowever, itop can integrate nagios for incident management (creating tickets).\nclose # It required a lot of time \u0026amp; effort to make my hands on, it\u0026rsquo;s not incredibly difficult - depends on what you usually do - but demanding. (compare to the nagios experience i have)\nTo keep their customers\u0026rsquo; time, they do bootcamps for 140$/h \u0026amp; have paid consultants.\nFor a production or business use, customers may pay for the professional or business itop solutions with consultants to help them integrating itop \u0026amp; keep a lot of time.\nI think one or more IT guys are needed to implement, maintain \u0026amp; using it (expecially with oql querries \u0026amp; various technos not covered).\nI saw on forums itop could implement customers\u0026rsquo; itsm for their need, but the discussion stopped here.\nI also like their blog.\nI am happy that i have found a way to understand itop \u0026amp; the surroundings properly \u0026amp; alone in a week, i hope so.\n","date":"2023-08-05","permalink":"/posts/itop-tour/","section":"Posts","summary":"combodo itop tour \u0026amp; creating a living","title":"combodo itop tour"},{"content":" understanding Nagios principles \u0026amp; deploying\na monitoring infrastructure using custom scripts introduction # For my work-study, i immersed myself in understanding Nagios.\nHere i expose what i\u0026rsquo;ve learned \u0026amp; what i\u0026rsquo;ve done with it.\nI\u0026rsquo;d be extremely grateful if you\u0026rsquo;d consider correcting me if i said something wrong.\nThis article mainly talks about Nagios as the Nagios Core solution.\npresentation # Nagios Core is an open source, widely used monitoring tool for hosts, applications \u0026amp; services.\nThe company behind Nagios, Nagios Enterprises, afford to make Nagios Core free \u0026amp; open source by their financing policy.\nThey provide non-free solutions to make the Nagios Core utilisation simplified, such as a more sophisticated dashboard - Nagios XI, or a better network implementation - Nagios Network Analyzer.\nThose solutions are improvers for Nagios Core, highly prefered for production use but not essential to use Nagios Core.\nside notes # Nagios Core source code can be found on Github, it is written in C language.\nYou may also consider, regarding your deontology or your use case, using your own metrics collector to serve them into a dashboard - using Prometheus \u0026amp; Grafana for examples.\nnagios principles # Covering the basics of Nagios Core according to monitoring windows \u0026amp; linux hosts with their services.\nfundamentals # Nagios Core need to be installed on a host, bare metal or in a vm - no official docker image available.\nTo monitor hosts, the Nagios server will execute a sequence of commands at a sheduled interval \u0026amp; will define the state of the monitored host/service according to the output of the sequence.\nThis series of checks can be customised according to what service you want to monitor.\nA simple \u0026amp; in use example can be the default HOST STATUS check by Nagios: the Nagios server send an echo request to the host - ping command. If it receive an echo reply back -\u0026gt; HOST STATUS: UP, else -\u0026gt; HOST STATUS: DOWN.\nApart from well-known protocols, to monitor the largest amount of services, Nagios lets its community post their own Projects.\nSince then, the community created \u0026amp; shared their free plugins \u0026amp; add-ons to monitor their needed services on Nagios - all in their Nagios Exchange platform.\nplugins # The commands used to monitor services are called plugins.\nPlugins are located in /usr/local/nagios/libexec/ with their name starting with check_*.\nThese plugins can be used as executable files to quickly check the status of services. Those actions are parts of \u0026ldquo;active monitoring\u0026rdquo;, which are usefull during pre-production tests.\nExample of an active check with check_http plugin.\n/usr/local/nagios/libexec/check_http -h display the help page\nfor the check_http plugin\nFollowing the check_http help page, this check can be executed on a host to check its http response.\n/usr/local/nagios/libexec/check_http -H 192.168.122.15 HTTP OK: HTTP/1.1 200 OK - 10975 bytes in 0.002 second response time |time=0.001620s;;;0.000000 size=10975B;;;0\nadd-ons # Plugins only monitor external metrics.\nTo monitor internal ones like system utilisation (cpu load, ram utilisation, disk usage etc.), Nagios use what they call add-ons.\nAdd-ons are splited software, an agent part is installed on the monitored host waiting for a gathering query \u0026amp; an executable file is on the nagios server to communicate with the agent api.\nThose add-ons often use tokens or passwords to verify the authenticity of the nagios server.\nFrom the Nagios server side, the add-ons will be used as executable files like plugins are.\nnagios configuration files # Nagios *.cfg configuration files are located in /usr/local/nagios/etc/.\n. ├── cgi.cfg ├── htpasswd.users ├── nagios.cfg ├── ressource.cfg └── objects ├── commands.cfg ├── contacts.cfg ├── localhost.cfg ├── printer.cfg ├── switch.cfg ├── templates.cfg ├── timeperiodes.cfg └── windows.cfg Since they are well documented inside \u0026amp; on the web, i\u0026rsquo;ll just outline their purpose.\nThe nagios.cfg is the main Nagios configuration file. It contains informations such as log files location - can be changed, locations of directories or individual hosts configuration files, services update interval \u0026amp; more.\nA standard htpasswd.users is created in the installation process \u0026amp; define the Nagios users passwords.\nCGIs check their cgi.cfg configuration file to gather user \u0026amp; groups permissions \u0026amp; rights. It also contains the path for Nagios frontend files.\nressource.cfg define macros used in hosts configuration files for sensitive informations. Also provides plugins paths - handy for moving plugins or adding custom ones.\n(example of \u0026ldquo;sensitive informations\u0026rdquo;: to monitor non public metrics about a database, it is needed at some point to log into using a username \u0026amp; a password)\nThe configuration files inside the objects directory are used to define commands, contacts, hosts, services etc. (more on that in hosts configuration files)\nhosts configuration files # Nagios monitor hosts by scheduling plugins tasks or calling add-ons and reporting the results on a control panel.\nTo define what checks should be made on which host, Nagios use Object Configuration Files.\nThese are *.cfg configuration files in which you define the host informations \u0026amp; the check_ commands that should be used.\nIt is recommended to create directories to manage your kinds of hosts - create a folder with all the *.cfg files for windows clients, linux servers etc.\nOtherwise, configuration files can be manually added to the nagios.cfg like the localhost.cfg by default.\ndeployment # Demonstration of what is said in how nagios works.\nDeploying an infrastructure based on the system monitoring of a Windows Host (server or client) \u0026amp; a Debian Host.\nnetwork plan # N a g i o s S e 1 r 9 v 2 e . r 1 6 8 . 1 2 2 . 2 0 3 N e W t i w n o d r o k w s S w H i 1 o t 9 s c 2 t h . 1 6 8 . 1 2 2 . 5 3 D e b i a n H 1 o 9 s 2 t . 1 6 8 . 1 2 2 . 1 6 5 windows host # Add-ons are needed to monitor hosts system activity.\nA lot of agents are available for windows \u0026amp; linux hosts. Nagios Cross-Platform Agent (NCPA) will be used because it is still recently maintained - by Nagios Enterprise.\n(note: for community maintained one, NSclient++ for windows \u0026amp; linux seems to be a good choice)\nTo install NCPA, need to start by downloading \u0026amp; executing the agent installer on the host.\nDownload the latest NCPA agent installer Here are the simple following steps for the install.\nBind IP has a default value of 0.0.0.0 to accept every ip address who request metrics - replaced it by the Nagios Server ip address.\nPort \u0026amp; Token can be changed.\ndebian host # NCPA will also be used for the debian host so that the check commands syntax will be the same for both host.\nI made an installation script for the debian agent, source code is on Github for debian 11 \u0026amp; 12.\nmkdir testing \u0026amp;\u0026amp; cd testing wget https://github.com/xeylou/nagios-introduction/debian-ncpa-install.sh chmod +x debian-ncpa-install.sh ./debian-ncpa-install.sh By using it, it will ask you the Nagios Server ip address \u0026amp; a custom token so that only it can gather metrics.\nChanges are made by changing the allowed_hosts \u0026amp; community_string variables in /usr/local/ncpa/etc/ncpa.cfg.\nFor other linux distributions than debian, the ncpa download page can be usefull.\nThe default 5693 port is used to transfer metrics.\nnagios server # The Nagios Server is in my case a Debian machine that host Nagios Core \u0026amp; the Nagios Plugins.\nI made an installation script for those by compiling code from source - tested on debian 11 \u0026amp; 12.\nmkdir testing \u0026amp;\u0026amp; cd testing wget https://github.com/xeylou/nagios-introduction/debian-nagios-install.sh chmod +x debian-nagios-install.sh ./debian-nagios-install.sh Nagios web interface can be reach at http://192.168.122.203/nagios with the username nagiosadmin \u0026amp; the password given at the beginning of the installation.\nCan check the connectivity to the agent on the windows host using the check_ncpa add-on command.\n/usr/local/nagios/libexec/check_ncpa.py -H 192.168.122.53 -t \u0026#39;windows-host\u0026#39; -P 5693 -M system/agent_version OK: Agent_version was [\u0026lsquo;2.4.1\u0026rsquo;]\nFor the debian one (changing values).\n/usr/local/nagios/libexec/check_ncpa.py -H 192.168.122.165 -t \u0026#39;debian-host\u0026#39; -P 5693 -M system/agent_version OK: Agent_version was [\u0026lsquo;2.4.1\u0026rsquo;]\n(note: the -H parameter is the host\u0026rsquo;s hostname or its ip address, -t is for the token created by the host during the agent installation process, -P the used port \u0026amp; -M the called value)\nExample of active monitoring of the cpu load for both - same syntax. Refer to the ncpa documentation to gather other metrics.\n/usr/local/nagios/libexec/check_ncpa.py -H 192.168.122.53 -t \u0026#39;windows-host\u0026#39; -P 5693 -M cpu/percent -w 20 -c 40 -q \u0026#39;aggregate=avg\u0026#39; OK: Percent was 4.70 % | \u0026lsquo;percent\u0026rsquo;=4.70%;20;40;\nHere on the debian host.\n/usr/local/nagios/libexec/check_ncpa.py -H 192.168.122.165 -t \u0026#39;debian-host\u0026#39; -P 5693 -M cpu/percent -w 20 -c 40 -q \u0026#39;aggregate=avg\u0026#39; OK: Percent was 0.00 % | \u0026lsquo;percent\u0026rsquo;=0.00%;20;40;\nTo add the hosts to the nagios web interface for passive monitoring: the Nagios Server requires their hosts .cfg configuration files.\nStarting by creating two directories to organise them: windows-hosts \u0026amp; debian-hosts (see hosts configuration files recommendation).\nmkdir /usr/local/nagios/etc/windows-hosts mkdir /usr/local/nagios/etc/debian-hosts Added them to the /usr/local/nagios/etc/nagios.cfg nagios configuration file.\n47 48 49 50 51 52 53 54 55 56 # You can also tell Nagios to process all config files (with a .cfg # extension) in a particular directory by using the cfg_dir # directive as shown below: cfg_dir=/usr/local/nagios/etc/windows-hosts cfg_dir=/usr/local/nagios/etc/debian-hosts #cfg_dir=/usr/local/nagios/etc/servers #cfg_dir=/usr/local/nagios/etc/printers #cfg_dir=/usr/local/nagios/etc/switches #cfg_dir=/usr/local/nagios/etc/routers These files should define the host using define host and the services to monitor by giving the check_* commands.\nHere is an example of the define host used for monitoring the debian host in /usr/local/nagios/debian-hosts/debian-host.cfg.\n1define host { 2 host_name debian-host 3 address 192.168.122.165 4 check_command check_ncpa!-t \u0026#39;debian-host\u0026#39; -P 5693 -M system/agent_version 5 max_check_attempts 5 6 check_interval 5 7 retry_interval 1 8 check_period 24x7 9 contacts nagiosadmin 10 notification_interval 60 11 notification_period 24x7 12 notifications_enabled 1 13 register 1 14} host_name is used for nagios to identify the host on its interface. The check_command defines the checked parameter for the HOST STATUS.\nHere is an example to implement the cpu load check to the configuration file by defining a service to monitor.\n16define service { 17 host_name debian-host 18 service_description CPU Load 19 check_command check_ncpa!-t \u0026#39;debian-host\u0026#39; -P 5693 -M cpu/percent -w 20 -c 40 -q \u0026#39;aggregate=avg\u0026#39; 20 max_check_attempts 5 21 check_interval 5 22 retry_interval 1 23 check_period 24x7 24 notification_interval 60 25 notification_period 24x7 26 contacts nagiosadmin 27 register 1 28} A command can be used to check errors in your *.cfg configuration files before restarting nagios service. Here an example with the debian host created.\n/usr/local/nagios/bin/nagios -v /usr/local/nagios/etc/debian-hosts/debian-host.cfg Finishing by restarting Nagios system service to make changes take effect.\nsystemctl restart nagios overview # Once logged into the nagios web interface, the hosts status can be see in the Hosts section of the Current Status.\nThe services status are available in the Services one.\n(the configuration files used was made by me \u0026amp; available on my Github)\nclose # I found the nagios documentation quite well explained (using \u0026amp; compiling nagios from source) although sometimes obsolete - relating to discontinued stuff or frustrating - some requirements missing from current repos.\nNagios Core is very very old, when doing my searching i was often finding myself reading forums posts from 2007-2009.\nAnother thought on Nagios Core is that its \u0026ldquo;unalive\u0026rdquo; today. Near nothing need to be changed in the code, because it does what it said on the tin.\nThe only things its team wants to work on now might be their cost solutions. However it\u0026rsquo;s for mission criticial tasks or companies wanted stuff that people charge off.\nThe real power is in the nagiosXI from a reddit user, and i found it sad from.\nOtherwise, i like nagios core flexibility by its check commands \u0026amp; its community that is still alive \u0026amp; contribute to plugins \u0026amp; add-ons.\n","date":"2023-07-25","permalink":"/posts/nagios-introduction/","section":"Posts","summary":"understanding Nagios principles \u0026amp; deploying","title":"nagios introduction"},{"content":" Note I try to keep this page as up to date as possible.\nYou can always contact me if the last update is too old. Work # I am a second-grade Network \u0026amp; Telecommunication bachelor student at University of Pau and the Adour Region.\nI do a work-study as an Network \u0026amp; System Administrator for a french IT service delivery company.\nFreetime # Exploring \u0026amp; creating Github repos about IT related stuff.\n","date":"2023-07-19","permalink":"/now/","section":"","summary":"Note I try to keep this page as up to date as possible.","title":"Now"},{"content":" Skills # My interests are oriented in networks \u0026amp; telecommunications, enjoying learning new technos on bare metal, using embedded or virtualization (gns3, packet tracer).\nI\u0026rsquo;ve been a linux enthusiast for years, having over 3 years of layer 2-7 administration of gnu/linux distributions for daily use (rhel, debian, alpine, arch, nixos).\nI have a strong background in virtualization \u0026amp; containerization using qemu/kvm, proxmox, gns3, cisco pt, docker + compose \u0026amp; k8s.\nI also love programming using java, python \u0026amp; bash.\nStudy # I have a French high-school bachelor general degree in mathematics \u0026amp; computer science.\nI am a second-year student at University of Pau and the Adour Region.\nHobbies # I like learning as much as i can about everything.\nI am an IT privacy \u0026amp; security enthusiast.\n","date":"2023-07-18","permalink":"/about/","section":"","summary":"Skills # My interests are oriented in networks \u0026amp; telecommunications, enjoying learning new technos on bare metal, using embedded or virtualization (gns3, packet tracer).","title":"About"},{"content":"","date":"0001-01-01","permalink":"/authors/","section":"Authors","summary":"","title":"Authors"},{"content":"","date":"0001-01-01","permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":"0001-01-01","permalink":"/tags/gnu/linux/","section":"Tags","summary":"","title":"gnu/linux"}]